{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook extracts all spelling and puncutation features from the set of queries found in SWC and SQS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries\n",
    "\n",
    "The following block of code loads all libraries needed for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import string\n",
    "import textstat\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from langdetect import detect\n",
    "from spellchecker import SpellChecker\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data Sets\n",
    "\n",
    "This block of code loads the data sets and extracts all unique queries from both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "allSessions = pickle.load( open( \"../Data/DataSets/SWC/SWC.p\", \"rb\" ) )\n",
    "allSessionsSQS = pickle.load( open( \"../Data/DataSets/SQS/SQS.p\", \"rb\" ) )\n",
    "allQueries = allSessions['query'].tolist() + allSessionsSQS['query'].tolist()\n",
    "allQueries = set(allQueries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Misspelled List\n",
    "\n",
    "Generates a list of commonly misspelled words by children from the KidSpell data set which is later used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kidsMispelled = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "with open('DataSets/KidSpell/Web_Search_Lab_Errors.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for row in spamreader:\n",
    "        if count == 0:\n",
    "            count += 1\n",
    "        else:\n",
    "            kidsMispelled.append(row[0])\n",
    "\n",
    "count = 0\n",
    "with open('DataSets/KidSpell/Web_Search_Informal_Errors.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for row in spamreader:\n",
    "        if count == 0:\n",
    "            count += 1\n",
    "        else:\n",
    "            kidsMispelled.append(row[0])\n",
    "    \n",
    "count = 0\n",
    "with open('DataSets/KidSpell/Essay_Writing_Errors.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for row in spamreader:\n",
    "        if count == 0:\n",
    "            count += 1\n",
    "        else:\n",
    "            kidsMispelled.append(row[1])\n",
    "\n",
    "kidsMispelled = set(kidsMispelled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Spelling Features\n",
    "\n",
    "The following block of code extracts features related to spelling errors and stores them in a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70112/70112 [2:41:38<00:00,  7.23it/s]   \n"
     ]
    }
   ],
   "source": [
    "spell = SpellChecker()\n",
    "\n",
    "spellingError = []\n",
    "oneOffError = []\n",
    "kidsError = []\n",
    "\n",
    "netModifiers = ['www', 'http', '.com', '.net', '.edu', '.org', '.gov', '.co', '.mil', '.com']\n",
    "\n",
    "with tqdm(total = len(allQueries) ) as pbar:\n",
    "    for query in allQueries:\n",
    "        query =  query.translate(str.maketrans('', '', string.punctuation))\n",
    "        website = [mod for mod in netModifiers if(mod in query)] \n",
    "        if not website:\n",
    "            try:\n",
    "                lang = detect(query)\n",
    "                misspelled = spell.unknown(query.split(\" \"))\n",
    "                found = 0\n",
    "                oneOff = 0\n",
    "                kidsMis = 0\n",
    "                for word in misspelled:\n",
    "                    if word in kidsMispelled:\n",
    "                        kidsMis +=1\n",
    "                    candid = spell.candidates(word)\n",
    "                    edits = spell.edit_distance_1(word)\n",
    "                    for can in candid:\n",
    "                        if can in edits:\n",
    "                            oneOff += 1\n",
    "                            break\n",
    "                oneOffError.append(oneOff)\n",
    "                spellingError.append(len(misspelled))\n",
    "                kidsError.append(kidsMis)\n",
    "\n",
    "            except:\n",
    "                oneOffError.append(-1)\n",
    "                spellingError.append(-1)\n",
    "                kidsError.append(-1)\n",
    "\n",
    "\n",
    "        else:\n",
    "            spellingError.append(0)\n",
    "            oneOffError.append(0)\n",
    "            kidsError.append(0)\n",
    "\n",
    "        pbar.update()\n",
    "    \n",
    "spelling = pd.DataFrame(data=spellingError, columns = ['numSpellingErrors'])\n",
    "spelling['query'] = allQueries\n",
    "spelling['offByOne'] = oneOffError\n",
    "spelling['kidsError'] = kidsError\n",
    "#spelling = spelling.set_index('query')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Punctuation And Casing Features\n",
    "\n",
    "The following block of code extracts spelling and casing features before adding them to the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70112/70112 [00:00<00:00, 261486.90it/s]\n"
     ]
    }
   ],
   "source": [
    "invalidcharacters= set(['!', ',', '.', '?'])\n",
    "punct = []\n",
    "casing = []\n",
    "with tqdm(total = len(allQueries) ) as pbar:\n",
    "    for query in allQueries:\n",
    "\n",
    "        if any(char in invalidcharacters for char in query):\n",
    "            if any(substring in query for substring in netModifiers):\n",
    "                punct.append(0)\n",
    "            else:\n",
    "                punct.append(1)\n",
    "        else:\n",
    "            punct.append(0)\n",
    "\n",
    "        if query.islower():\n",
    "            casing.append(0)\n",
    "        else:\n",
    "            casing.append(1)\n",
    "        pbar.update()\n",
    "        \n",
    "spelling['punct'] = punct\n",
    "spelling['casing'] = casing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return Feature Set\n",
    "\n",
    "Returns dataframe with spelling and punctuation features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(spelling, open( \"Pickles/SPFeat.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
