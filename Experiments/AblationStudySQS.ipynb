{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognizeSearcher(params, feats, featType):\n",
    "    \n",
    "    tnOva = 0\n",
    "    fpOva = 0\n",
    "    fnOva = 0\n",
    "    tpOva = 0\n",
    "    testAccOva = 0\n",
    "    nSplits = 5\n",
    "    x = 0\n",
    "    \n",
    "    accByNum = []\n",
    "    outputAll = []\n",
    "    outputQ = []\n",
    "\n",
    "    kfold = KFold(n_splits=nSplits, random_state=20210530, shuffle=True)\n",
    "    \n",
    "    randomNumber = 20210530 \n",
    "    \n",
    "    X = SWC[feats]\n",
    "    y = SWC['class']\n",
    "   \n",
    "    if params['scaler']:\n",
    "        if params['classWeight']:\n",
    "            tunePipe = Pipeline([\n",
    "            ('standardize', params['scaler']),\n",
    "            ('classify', RandomForestClassifier(n_estimators=params['numEstimators'], bootstrap = params['bootStrap'],\n",
    "                                                criterion= params['criterion'], class_weight = params['classWeight'], \n",
    "                                                random_state= randomNumber, n_jobs = -1))\n",
    "            ])\n",
    "        else:\n",
    "            tunePipe = Pipeline([\n",
    "            ('standardize', params['scaler']),\n",
    "            ('classify', RandomForestClassifier(n_estimators=params['numEstimators'], bootstrap = params['bootStrap'],\n",
    "                                                criterion= params['criterion'], random_state= randomNumber, n_jobs = -1))\n",
    "            ])\n",
    "    else:\n",
    "        if params['classWeight']:\n",
    "            tunePipe = Pipeline([\n",
    "            ('classify', RandomForestClassifier(n_estimators=params['numEstimators'], bootstrap = params['bootStrap'],\n",
    "                                                criterion= params['criterion'], class_weight = params['classWeight'], \n",
    "                                                random_state= randomNumber, n_jobs = -1))\n",
    "            ])\n",
    "        else:\n",
    "            tunePipe = Pipeline([\n",
    "            ('classify', RandomForestClassifier(n_estimators=params['numEstimators'], bootstrap = params['bootStrap'],\n",
    "                                                criterion= params['criterion'], random_state= randomNumber, n_jobs = -1))\n",
    "            ])\n",
    "                \n",
    "\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "\n",
    "        rng = np.random.RandomState(randomNumber)\n",
    "    \n",
    "        trainSQS = SQS.sample(frac=0.20, random_state=rng)\n",
    "        testMask = pd.Series(True, index=SQS.index)\n",
    "        testMask[trainSQS.index] = False\n",
    "        test = SQS[testMask].copy()\n",
    "\n",
    "        \n",
    "        subTrainX = trainSQS[feats]\n",
    "        subTrainY = trainSQS['class']\n",
    "        \n",
    "        trainX, testX = X.iloc[train_index], X.iloc[test_index]\n",
    "        trainY, testY = y.iloc[train_index], y.iloc[test_index]\n",
    "        trainX = pd.concat([trainX,subTrainX])\n",
    "        trainY = pd.concat([trainY,subTrainY])\n",
    "        trainX = trainX.fillna(0)\n",
    "        tunePipe.fit(trainX, trainY)\n",
    "\n",
    "        testAccOva +=  accuracy_score(test['class'], tunePipe.predict(test[feats]))\n",
    "        tn, fp, fn, tp = confusion_matrix(test['class'], tunePipe.predict(test[feats])).ravel()\n",
    "        tnOva += tn\n",
    "        fpOva += fp\n",
    "        fnOva += fn\n",
    "        tpOva += tp\n",
    "        outputAll.append(tunePipe.predict(test[feats]))\n",
    "\n",
    "        \n",
    "    pickle.dump( outputAll, open( \"Pickles/OutputAll\" + str(featType) + \"SQS.p\", \"wb\" ) )\n",
    "\n",
    "   \n",
    "    results = [featType, round(testAccOva/5,3), tnOva/5, fpOva/5, round(((tnOva/5)/((tnOva/5)+ (fpOva/5))),3), fnOva/5, tpOva/5,round(((tpOva/5)/((tpOva/5)+ (fnOva/5))),3),]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SWC = pickle.load( open( \"Pickles/SWCFeatNoTune.p\", \"rb\" ) )\n",
    "SQS =  pickle.load( open( \"../FeatureExtraction/DataSets/SQSFeatures/SQSFeat.p\", \"rb\" ) )\n",
    "bestParameters = pickle.load( open( \"Pickles/BestParam.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(SQS.columns)\n",
    "features.remove('class')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['numSpellingErrors',\n",
       " 'offByOne',\n",
       " 'kidsError',\n",
       " 'punct',\n",
       " 'casing',\n",
       " 'coreVocab',\n",
       " 'nonCoreVocab',\n",
       " 'minAoA',\n",
       " 'maxAoA',\n",
       " 'ratioAoA',\n",
       " 'queryComplexity',\n",
       " 'SVEN',\n",
       " 'top250SterCount',\n",
       " 'top250SterRatAnt',\n",
       " 'top250SterRatCon',\n",
       " 'top250NonSterCount',\n",
       " 'top250NonSterRatAnt',\n",
       " 'top250NonSterRatCon',\n",
       " 'top10SterCount',\n",
       " 'top10SterRatAnt',\n",
       " 'top10SterAntCon',\n",
       " 'top50NonSterCount',\n",
       " 'top50NonSterRatAnt',\n",
       " 'top50NonSterAntCon',\n",
       " 'tfidfAll',\n",
       " 'tfidfS',\n",
       " 'tfidfNS',\n",
       " 'stopCount',\n",
       " 'com',\n",
       " 'net',\n",
       " 'org',\n",
       " 'edu',\n",
       " 'gov',\n",
       " 'http',\n",
       " 'AND',\n",
       " 'OR',\n",
       " 'quotes',\n",
       " 'inter',\n",
       " 'totalSyl',\n",
       " 'avgSyl',\n",
       " 'simWords',\n",
       " 'comWords',\n",
       " 'greatestSyl',\n",
       " 'leastSyl',\n",
       " 'numChars',\n",
       " 'numWords',\n",
       " 'avgLenWord',\n",
       " 'ld',\n",
       " 'ls1',\n",
       " 'ls2',\n",
       " 'vs1',\n",
       " 'vs2',\n",
       " 'cvs1',\n",
       " 'ndw',\n",
       " 'ttr',\n",
       " 'cttr',\n",
       " 'rttr',\n",
       " 'logttr',\n",
       " 'lv',\n",
       " 'vv1',\n",
       " 'svv1',\n",
       " 'cvv1',\n",
       " 'vv2',\n",
       " 'nv',\n",
       " 'adjv',\n",
       " 'cc',\n",
       " 'cd',\n",
       " 'dt',\n",
       " 'ex',\n",
       " 'fw',\n",
       " 'in',\n",
       " 'jj',\n",
       " 'jjr',\n",
       " 'jjs',\n",
       " 'md',\n",
       " 'nn',\n",
       " 'nnp',\n",
       " 'nnps',\n",
       " 'nns',\n",
       " 'pdt',\n",
       " 'pos',\n",
       " 'prp',\n",
       " 'rb',\n",
       " 'rbr',\n",
       " 'rbs',\n",
       " 'rp',\n",
       " 'sym',\n",
       " 'to',\n",
       " 'uh',\n",
       " 'vb',\n",
       " 'vbd',\n",
       " 'vbg',\n",
       " 'vbn',\n",
       " 'vbp',\n",
       " 'vbz',\n",
       " 'wdt',\n",
       " 'wp',\n",
       " 'wrb',\n",
       " 'nn nn',\n",
       " 'jj nn',\n",
       " 'nn nns',\n",
       " 'to vb',\n",
       " 'jj nns',\n",
       " 'jj to',\n",
       " 'nn in',\n",
       " 'nns in',\n",
       " 'in nn',\n",
       " 'dt nn',\n",
       " 'jj nn nn',\n",
       " 'nn nn nn',\n",
       " 'jj to vb',\n",
       " 'nn nn nns',\n",
       " 'to vb nn',\n",
       " ' Level0',\n",
       " ' Level1',\n",
       " ' Level2',\n",
       " ' Level3',\n",
       " ' Level4',\n",
       " ' Level5',\n",
       " ' Level6',\n",
       " ' Level7',\n",
       " ' MeanLevel',\n",
       " 'numQueries',\n",
       " 'numClicks',\n",
       " 'numClicksPerQuery',\n",
       " 'meanClickPosition',\n",
       " 'queryDistance',\n",
       " 'timeQueries',\n",
       " 'uniqueQueries',\n",
       " 'allSameQueries',\n",
       " 'repeatQueries',\n",
       " 'uniqueClicks',\n",
       " 'allSameClicks',\n",
       " 'repeatClicks',\n",
       " 'timeClicks',\n",
       " 'clickDistance']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "P3Feats = ['ld',\n",
    " 'ls1',\n",
    " 'ls2',\n",
    " 'vs1',\n",
    " 'vs2',\n",
    " 'cvs1',\n",
    " 'ndw',\n",
    " 'ttr',\n",
    " 'cttr',\n",
    " 'rttr',\n",
    " 'logttr',\n",
    " 'lv',\n",
    " 'vv1',\n",
    " 'svv1',\n",
    " 'cvv1',\n",
    " 'vv2',\n",
    " 'nv',\n",
    " 'adjv',\n",
    " 'numSpellingErrors',\n",
    " 'offByOne',\n",
    " 'kidsError',\n",
    " 'coreVocab',\n",
    " 'nonCoreVocab',\n",
    " 'minAoA',\n",
    " 'maxAoA',\n",
    " 'ratioAoA',\n",
    " 'queryComplexity',\n",
    " 'SVEN',\n",
    " 'top250SterCount',\n",
    " 'top250SterRatAnt',\n",
    " 'top250SterRatCon',\n",
    " 'top250NonSterCount',\n",
    " 'top250NonSterRatAnt',\n",
    " 'top250NonSterRatCon',\n",
    " 'top50SterCount',\n",
    " 'top50SterRatAnt',\n",
    " 'top50SterAntCon',\n",
    " 'top50NonSterCount',\n",
    " 'top50NonSterRatAnt',\n",
    " 'top50NonSterAntCon',\n",
    " 'tfidfAll',\n",
    " 'tfidfS',\n",
    " 'tfidfNS'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DC1Feats = ['ndw',\n",
    " 'ttr',\n",
    " 'cttr',\n",
    " 'rttr',\n",
    " 'logttr',\n",
    " 'lv',\n",
    " 'vv1',\n",
    " 'svv1',\n",
    " 'cvv1',\n",
    " 'vv2',\n",
    " 'nv',\n",
    " 'adjv',\n",
    " 'totalSyl',\n",
    " 'avgSyl',\n",
    " 'simWords',\n",
    " 'comWords',\n",
    " 'greatestSyl',\n",
    " 'leastSyl',\n",
    " 'numChars',\n",
    " 'numWords',\n",
    " 'avgLenWord',\n",
    " 'minAoA',\n",
    " 'maxAoA',\n",
    " 'queryComplexity',\n",
    " 'stopCount',\n",
    " 'com',\n",
    " 'net',\n",
    " 'org',\n",
    " 'edu',\n",
    " 'gov',\n",
    " 'http',\n",
    " 'AND',\n",
    " 'OR',\n",
    " 'quotes',\n",
    " 'inter',\n",
    " 'numSpellingErrors',\n",
    " 'offByOne',\n",
    " 'kidsError',\n",
    " 'punct',\n",
    " 'casing',\n",
    " ' Level0',\n",
    " ' Level1',\n",
    " ' Level2',\n",
    " ' Level3',\n",
    " ' Level4',\n",
    " ' Level5',\n",
    " ' Level6',\n",
    " ' Level7',\n",
    " ' MeanLevel',\n",
    " 'cc',\n",
    " 'cd',\n",
    " 'dt',\n",
    " 'ex',\n",
    " 'fw',\n",
    " 'in',\n",
    " 'jj',\n",
    " 'jjr',\n",
    " 'jjs',\n",
    " 'md',\n",
    " 'nn',\n",
    " 'nnp',\n",
    " 'nnps',\n",
    " 'nns',\n",
    " 'pdt',\n",
    " 'pos',\n",
    " 'prp',\n",
    " 'rb',\n",
    " 'rbr',\n",
    " 'rbs',\n",
    " 'rp',\n",
    " 'sym',\n",
    " 'to',\n",
    " 'uh',\n",
    " 'vb',\n",
    " 'vbd',\n",
    " 'vbg',\n",
    " 'vbn',\n",
    " 'vbp',\n",
    " 'vbz',\n",
    " 'wdt',\n",
    " 'wp',\n",
    " 'wrb',\n",
    " 'nn nn',\n",
    " 'jj nn',\n",
    " 'nn nns',\n",
    " 'to vb',\n",
    " 'jj nns',\n",
    " 'jj to',\n",
    " 'nn in',\n",
    " 'nns in',\n",
    " 'in nn',\n",
    " 'dt nn',\n",
    " 'jj nn nn',\n",
    " 'nn nn nn',\n",
    " 'jj to vb',\n",
    " 'nn nn nns',\n",
    " 'to vb nn',\n",
    " 'repeatClicks',\n",
    " 'clickDistance',\n",
    " 'meanClickPosition',\n",
    " 'numClicks',\n",
    " 'numClicksPerQuery',\n",
    " 'numQueries',\n",
    " 'timeClicks',\n",
    " 'uniqueQueries',\n",
    " 'allSameClicks',\n",
    " 'uniqueClicks',\n",
    " 'allSameQueries',\n",
    " 'queryDistance',\n",
    " 'timeQueries',\n",
    " 'repeatQueries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextFeat = ['cc',\n",
    " 'cd',\n",
    " 'dt',\n",
    " 'ex',\n",
    " 'fw',\n",
    " 'in',\n",
    " 'jj',\n",
    " 'jjr',\n",
    " 'jjs',\n",
    " 'md',\n",
    " 'nn',\n",
    " 'nnp',\n",
    " 'nnps',\n",
    " 'nns',\n",
    " 'pdt',\n",
    " 'pos',\n",
    " 'prp',\n",
    " 'rb',\n",
    " 'rbr',\n",
    " 'rbs',\n",
    " 'rp',\n",
    " 'sym',\n",
    " 'to',\n",
    " 'uh',\n",
    " 'vb',\n",
    " 'vbd',\n",
    " 'vbg',\n",
    " 'vbn',\n",
    " 'vbp',\n",
    " 'vbz',\n",
    " 'wdt',\n",
    " 'wp',\n",
    " 'wrb',\n",
    " 'nn nn',\n",
    " 'jj nn',\n",
    " 'nn nns',\n",
    " 'to vb',\n",
    " 'jj nns',\n",
    " 'jj to',\n",
    " 'nn in',\n",
    " 'nns in',\n",
    " 'in nn',\n",
    " 'dt nn',\n",
    " 'jj nn nn',\n",
    " 'nn nn nn',\n",
    " 'jj to vb',\n",
    " 'nn nn nns',\n",
    " 'to vb nn',\n",
    " ' Level0',\n",
    " ' Level1',\n",
    " ' Level2',\n",
    " ' Level3',\n",
    " ' Level4',\n",
    " ' Level5',\n",
    " ' Level6',\n",
    " ' Level7',\n",
    " ' MeanLevel',\n",
    " 'totalSyl',\n",
    " 'avgSyl',\n",
    " 'simWords',\n",
    " 'comWords',\n",
    " 'greatestSyl',\n",
    " 'leastSyl',\n",
    " 'numChars',\n",
    " 'numWords',\n",
    " 'avgLenWord',\n",
    " 'ld',\n",
    " 'ls1',\n",
    " 'ls2',\n",
    " 'vs1',\n",
    " 'vs2',\n",
    " 'cvs1',\n",
    " 'ndw',\n",
    " 'ttr',\n",
    " 'cttr',\n",
    " 'rttr',\n",
    " 'logttr',\n",
    " 'lv',\n",
    " 'vv1',\n",
    " 'svv1',\n",
    " 'cvv1',\n",
    " 'vv2',\n",
    " 'nv',\n",
    " 'adjv',\n",
    " 'numSpellingErrors',\n",
    " 'offByOne',\n",
    " 'kidsError',\n",
    " 'punct',\n",
    " 'casing',\n",
    " 'coreVocab',\n",
    " 'nonCoreVocab',\n",
    " 'minAoA',\n",
    " 'maxAoA',\n",
    " 'ratioAoA',\n",
    " 'queryComplexity',\n",
    " 'SVEN',\n",
    " 'top250SterCount',\n",
    " 'top250SterRatAnt',\n",
    " 'top250SterRatCon',\n",
    " 'top250NonSterCount',\n",
    " 'top250NonSterRatAnt',\n",
    " 'top250NonSterRatCon',\n",
    " 'top50SterCount',\n",
    " 'top50SterRatAnt',\n",
    " 'top50SterAntCon',\n",
    " 'top50NonSterCount',\n",
    " 'top50NonSterRatAnt',\n",
    " 'top50NonSterAntCon',\n",
    " 'tfidfAll',\n",
    " 'tfidfS',\n",
    " 'tfidfNS',\n",
    " 'stopCount',\n",
    " 'com',\n",
    " 'net',\n",
    " 'org',\n",
    " 'edu',\n",
    " 'gov',\n",
    " 'http',\n",
    " 'AND',\n",
    " 'OR',\n",
    " 'quotes',\n",
    " 'inter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SessionFeats = ['repeatClicks',\n",
    " 'clickDistance',\n",
    " 'meanClickPosition',\n",
    " 'numClicks',\n",
    " 'numClicksPerQuery',\n",
    " 'numQueries',\n",
    " 'timeClicks',\n",
    " 'uniqueQueries',\n",
    " 'allSameClicks',\n",
    " 'uniqueClicks',\n",
    " 'allSameQueries',\n",
    " 'queryDistance',\n",
    " 'timeQueries',\n",
    " 'repeatQueries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['top50SterAntCon', 'top50SterRatAnt', 'top50SterCount'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4424a589f076>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mRYSe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecognizeSearcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestParameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RYSe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mP3Results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecognizeSearcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestParameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP3Feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'P3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mDC1Results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecognizeSearcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestParameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDC1Feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DC1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtextResults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecognizeSearcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestParameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTextFeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TextBased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msessionResults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecognizeSearcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestParameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSessionFeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SessionBased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-8c4c072a0967>\u001b[0m in \u001b[0;36mrecognizeSearcher\u001b[0;34m(params, feats, featType)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mrandomNumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20210530\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSWC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSWC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2908\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2910\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1302\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;31m# we skip the warning on Categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['top50SterAntCon', 'top50SterRatAnt', 'top50SterCount'] not in index\""
     ]
    }
   ],
   "source": [
    "RYSe = recognizeSearcher(bestParameters, features, 'RYSe')\n",
    "P3Results = recognizeSearcher(bestParameters, P3Feats, 'P3')\n",
    "DC1Results = recognizeSearcher(bestParameters, DC1Feats, 'DC1')\n",
    "textResults = recognizeSearcher(bestParameters, TextFeat, 'TextBased')\n",
    "sessionResults = recognizeSearcher(bestParameters, SessionFeats, 'SessionBased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allResults = pd.DataFrame(data = [RYSe,P3Results,DC1Results,textResults,sessionResults  ], columns = [\"Type\",\"Acc\", \"TN\", \"FP\", \"TNR\", \"FN\", \"TP\", \"TPR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( allResults, open( \"Pickles/AblationSQS.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
