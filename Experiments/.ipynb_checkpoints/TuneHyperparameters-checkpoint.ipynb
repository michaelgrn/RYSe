{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs grid search in order to tune the hyper parameters for our model. We split our dataset into train/tune and then run each trained model numIts times and average the results, looking for the highest true positive score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries\n",
    "\n",
    "In the following block of code we import the used libraries and set the seed value for the numpy randomstate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "rng = np.random.RandomState(20210414)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data Set and Create Train/Tune\n",
    "\n",
    "In the following block of code we load SWC and then split it into test/tune for the gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SWCAll =  pickle.load( open( \"../FeatureExtraction/DataSets/SWCFeatures/SWCFeat.p\", \"rb\" ) )\n",
    "\n",
    "train = SWCAll.sample(frac=0.80, random_state=rng)\n",
    "subTrain = train.sample(frac=0.80, random_state=rng)\n",
    "tuneMask = pd.Series(True, index=train.index)\n",
    "tuneMask[subTrain.index] = False\n",
    "tune = train[tuneMask].copy()\n",
    "\n",
    "feat = subTrain.columns.tolist()\n",
    "feat.remove('class')\n",
    "featCols = feat\n",
    "outCol = 'class'\n",
    "\n",
    "subTrainX = subTrain[featCols]\n",
    "subTrainY = subTrain[outCol]\n",
    "\n",
    "tuneX = tune[featCols]\n",
    "tuneY = tune[outCol]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Gridsearch\n",
    "\n",
    "In the following block of code we perform the gridsearch, returning storing the model with the highest true positive parameters in bestParam. If two models share at TP, we then compare TN, storing the parameters of the one with the highest TP and TN. The seperation into two major loops is to distinguish between class_weight none and balanced; as we encounted difficulty using the classWeightParam to declare these parameters (so they are hard coded). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/160 [00:05<14:41,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "922.2\n",
      "{'numEstimators': 50, 'bootStrap': True, 'criterion': 'gini', 'classWeight': 'balanced', 'scaler': StandardScaler()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 2/160 [00:11<15:06,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "924.6\n",
      "{'numEstimators': 50, 'bootStrap': True, 'criterion': 'gini', 'classWeight': 'balanced', 'scaler': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 3/160 [00:19<16:39,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "933.6\n",
      "{'numEstimators': 50, 'bootStrap': True, 'criterion': 'entropy', 'classWeight': 'balanced', 'scaler': StandardScaler()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/160 [00:40<21:56,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941.4\n",
      "{'numEstimators': 50, 'bootStrap': False, 'criterion': 'gini', 'classWeight': 'balanced', 'scaler': StandardScaler()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 7/160 [01:02<24:58,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "951.8\n",
      "{'numEstimators': 50, 'bootStrap': False, 'criterion': 'entropy', 'classWeight': 'balanced', 'scaler': StandardScaler()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 8/160 [01:14<26:20, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "961.2\n",
      "{'numEstimators': 50, 'bootStrap': False, 'criterion': 'entropy', 'classWeight': 'balanced', 'scaler': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 24/160 [09:13<1:25:45, 37.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "963.6\n",
      "{'numEstimators': 150, 'bootStrap': False, 'criterion': 'entropy', 'classWeight': 'balanced', 'scaler': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 136/160 [2:54:40<57:23, 143.49s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "965.2\n",
      "{'numEstimators': 350, 'bootStrap': False, 'criterion': 'entropy', 'classWeight': '', 'scaler': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [3:50:54<00:00, 86.59s/it] \n"
     ]
    }
   ],
   "source": [
    "bestTP = 0\n",
    "bestTN = 0\n",
    "numIts = 5\n",
    "\n",
    "numEstimatorParam = [50, 100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
    "bootStrapParam = [True, False]\n",
    "criterionParam = ['gini', 'entropy']\n",
    "classWeightParam = ['None', 'balanced']\n",
    "scalers = [StandardScaler(), '']\n",
    "\n",
    "bestParam =\t{\n",
    "  \"numEstimators\": 0,\n",
    "  \"bootStrap\": False,\n",
    "  \"criterion\": \"\",\n",
    "  \"classWeight\" : \"\",\n",
    "  \"scaler\" : \"\"\n",
    "}\n",
    "\n",
    "length = (len(numEstimatorParam)*len(bootStrapParam)*len(criterionParam)*len(classWeightParam)*len(scalers))\n",
    "\n",
    "with tqdm(total = length) as pbar:\n",
    "    for numE in numEstimatorParam:\n",
    "        for bS in bootStrapParam:\n",
    "            for c in criterionParam:\n",
    "                for scale in scalers:\n",
    "                    \n",
    "                    tpAvg = 0\n",
    "                    tnAvg = 0\n",
    "                    \n",
    "                    for x in range(numIts):\n",
    "                       \n",
    "                        if scale:\n",
    "                            tunePipe = Pipeline([\n",
    "                                ('standardize', scale),\n",
    "                                ('classify', RandomForestClassifier(criterion = c, n_estimators=numE, bootstrap = bS, class_weight = 'balanced', n_jobs=-1, random_state = rng ))\n",
    "                            ])\n",
    "                        else:\n",
    "                            tunePipe = Pipeline([\n",
    "                                ('classify', RandomForestClassifier(criterion = c, n_estimators=numE, bootstrap = bS, class_weight = 'balanced', n_jobs=-1, random_state = rng )) \n",
    "                            ])\n",
    "                        \n",
    "                        tunePipe.fit(subTrainX, subTrainY)\n",
    "\n",
    "                        tuneAcc = accuracy_score(tuneY, tunePipe.predict(tuneX))\n",
    "                        tn, fp, fn, tp = confusion_matrix(tuneY, tunePipe.predict(tuneX)).ravel()\n",
    "                        tpAvg += tp\n",
    "                        tnAvg += tn\n",
    "                        \n",
    "                    tpAvg = tpAvg/numIts\n",
    "                    tnAvg = tnAvg/numIts\n",
    "\n",
    "                    \n",
    "                    if tpAvg > bestTP:\n",
    "                        \n",
    "                        bestTP = tpAvg\n",
    "                        bestTN = tnAvg\n",
    "                        bestParam[\"numEstimators\"] = numE\n",
    "                        bestParam[\"bootStrap\"] = bS\n",
    "                        bestParam[\"criterion\"] = c\n",
    "                        bestParam[\"classWeight\"] = 'balanced'\n",
    "                        bestParam[\"scaler\"] = scale\n",
    "                        print(tpAvg)\n",
    "                        print(bestParam)\n",
    "                    \n",
    "                    if tpAvg == bestTP:\n",
    "                        \n",
    "                        if tnAvg >bestTN:\n",
    "                            \n",
    "                            bestTP = tpAvg\n",
    "                            bestTN = tnAvg\n",
    "                            bestParam[\"numEstimators\"] = numE\n",
    "                            bestParam[\"bootStrap\"] = bS\n",
    "                            bestParam[\"criterion\"] = c\n",
    "                            bestParam[\"classWeight\"] = 'balanced'\n",
    "                            bestParam[\"scaler\"] = scale\n",
    "\n",
    "                    pbar.update()\n",
    "                    \n",
    "    for numE in numEstimatorParam:\n",
    "        for bS in bootStrapParam:\n",
    "            for c in criterionParam:\n",
    "                for scale in scalers:\n",
    "                    \n",
    "                    tpAvg = 0\n",
    "                    tnAvg = 0\n",
    "                    \n",
    "                    for x in range(numIts):\n",
    "                        \n",
    "                        if scale:\n",
    "                            tunePipe = Pipeline([\n",
    "                                ('standardize', scale),\n",
    "                                ('classify', RandomForestClassifier(criterion = c, n_estimators=numE, bootstrap = bS, n_jobs=-1, random_state = rng))\n",
    "                            ])\n",
    "                        else:\n",
    "                            tunePipe = Pipeline([\n",
    "                                 ('classify', RandomForestClassifier(criterion = c, n_estimators=numE, bootstrap = bS, n_jobs=-1, random_state = rng))\n",
    "                            ])\n",
    "                        tunePipe.fit(subTrainX, subTrainY)\n",
    "\n",
    "                        tuneAcc = accuracy_score(tuneY, tunePipe.predict(tuneX))\n",
    "                        tn, fp, fn, tp = confusion_matrix(tuneY, tunePipe.predict(tuneX)).ravel()\n",
    "                        tpAvg += tp\n",
    "                        tnAvg += tn\n",
    "                        \n",
    "                    tpAvg = tpAvg/numIts\n",
    "                    tnAvg = tnAvg/numIts\n",
    "\n",
    "                    if tpAvg > bestTP:\n",
    "                        bestTP = tpAvg\n",
    "                        bestTN = tnAvg\n",
    "                        bestParam[\"numEstimators\"] = numE\n",
    "                        bestParam[\"bootStrap\"] = bS\n",
    "                        bestParam[\"criterion\"] = c\n",
    "                        bestParam[\"classWeight\"] = ''\n",
    "                        bestParam[\"scaler\"] = scale\n",
    "                        print(tpAvg)\n",
    "                        print(bestParam)\n",
    "\n",
    "                    if tpAvg == bestTP:\n",
    "                        \n",
    "                        if tnAvg >bestTN:\n",
    "                            \n",
    "                            bestTP = tpAvg\n",
    "                            bestTN = tnAvg\n",
    "                            bestParam[\"numEstimators\"] = numE\n",
    "                            bestParam[\"bootStrap\"] = bS\n",
    "                            bestParam[\"criterion\"] = c\n",
    "                            bestParam[\"classWeight\"] = ''\n",
    "                            bestParam[\"scaler\"] = scale\n",
    "\n",
    "                    pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Tune From Data Sets\n",
    "\n",
    "In the following block of code we remove the entries we used in order to perform our hyper parameter tuning from SWC, both the original data set as well as the data set merged with the aggregated features; as both will be used in our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SWC = pickle.load( open( \"../Data/DataSets/SWC/SWC.p\", \"rb\" ) )\n",
    "toRemove = tune.index.tolist()\n",
    "SWCFeatNoTune = SWCAll.drop(tune.index)\n",
    "SWCNoTune = SWC[~SWC['sID'].isin(toRemove)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return Data Sets with Tune Removed\n",
    "\n",
    "The following block of code saves the data sets modified in the previous block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(SWCFeatNoTune, open( \"Pickles/SWCFeatNoTune.p\", \"wb\" ))\n",
    "pickle.dump(SWCNoTune, open( \"Pickles/SWCNoTune.p\", \"wb\" ))\n",
    "pickle.dump(bestParam, open( \"Pickles/BestParam.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
