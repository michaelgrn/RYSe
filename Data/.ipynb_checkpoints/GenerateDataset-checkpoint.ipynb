{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in this notebook generates the Data Sets for our experiments by drawing on several data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "import xmltodict\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DMOZ\n",
    "\n",
    "This loads the DMOZ tages which are used to determine whether a website should be tagged as \"designed for children\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sterSites = []\n",
    "with open('DataSources/DMOZ/URL Classification.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "        for row in csv_reader:\n",
    "            if(row[2] == 'Kids'):\n",
    "                sterSites.append(row[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitQueryClicksAOL(data):\n",
    "    sample = []\n",
    "    for session in data:\n",
    "        currentQuery = session[0][1]\n",
    "        first = True\n",
    "        currentTime = -1\n",
    "        newSession = []\n",
    "        for query in session:\n",
    "            if first and query[1] == currentQuery and (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif first and query[1] == currentQuery and not (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "            elif query[1] != currentQuery and (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif query[1] != currentQuery and not (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "            # and has a click\n",
    "            # and doesn't have a click\n",
    "            ##if the query is the same \n",
    "            elif query[1] == currentQuery and (query[2] != currentTime) and (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif query[1] == currentQuery and (query[2] == currentTime) and (query[3]): \n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif query[1] == currentQuery and (query[2] == currentTime) and not (query[3]): \n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "            elif query[1] == currentQuery and not (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "            currentQuery = query[1]\n",
    "            currentTime = query[2]\n",
    "            first = False\n",
    "        sample.append(newSession)\n",
    "    return sample\n",
    "\n",
    "def splitQueryClicksTREC(data):\n",
    "    sample = []\n",
    "    for session in data:\n",
    "        currentQuery = session[0][1]\n",
    "        first = True\n",
    "        currentTime = -1\n",
    "        newSession = []\n",
    "        for query in session:\n",
    "            if first and query[1] == currentQuery and (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif first and query[1] == currentQuery and not (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "            elif query[1] != currentQuery and (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif query[1] != currentQuery and not (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "            # and has a click\n",
    "            # and doesn't have a click\n",
    "            ##if the query is the same \n",
    "            elif query[1] == currentQuery and (query[2] != currentTime) and (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif query[1] == currentQuery and (query[2] == currentTime): \n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif query[1] == currentQuery and not (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "            currentQuery = query[1]\n",
    "            currentTime = query[2]\n",
    "            first = False\n",
    "            #print(query)\n",
    "        sample.append(newSession)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Process AOL\n",
    "\n",
    "This block of code loads the AOL query logs and seperates sessions into two types, one that contain websites designed for our Stereotype, and sesions that do not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1026700 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'archSites' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ff0c136f8a76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marchSites\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                     \u001b[0msterSessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0mster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'archSites' is not defined"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "#loads query logs\n",
    "for filename in glob.glob(\"DataSources/AOL/*.txt\"):\n",
    "    queryLog = []\n",
    "    with open(filename) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter = '\\t')\n",
    "        lineCount = 0\n",
    "        for row in csv_reader:\n",
    "            if(lineCount > 0):\n",
    "                queryLog.append(row)\n",
    "            lineCount += 1\n",
    "    \n",
    "    currentUser = queryLog[0][0]\n",
    "    date = datetime.strptime(queryLog[0][2], \"%Y-%m-%d %H:%M:%S\")\n",
    "    currentTime = datetime.timestamp(date)\n",
    "\n",
    "    sessions = []\n",
    "    session = []\n",
    "    \n",
    "    #seperates query logs into sessions\n",
    "    for row in queryLog:\n",
    "        tempUser = row[0]\n",
    "        date = datetime.strptime(row[2], \"%Y-%m-%d %H:%M:%S\")\n",
    "        tempTime = datetime.timestamp(date)\n",
    "        if(tempUser != currentUser):\n",
    "            sessions.append(session)\n",
    "            session = []\n",
    "            currentUser = tempUser\n",
    "            date = datetime.strptime(row[2], \"%Y-%m-%d %H:%M:%S\")\n",
    "            tempTime = datetime.timestamp(date)\n",
    "            currentTime = tempTime\n",
    "        if(tempTime > (currentTime + (60*60))):\n",
    "            sessions.append(session)\n",
    "            session = []\n",
    "            currentTime = tempTime\n",
    "        session.append(row)\n",
    "  \n",
    "\n",
    "    sterSessions = []\n",
    "    notSterSessions = []\n",
    "    ster = False\n",
    "    \n",
    "    #seperates sessions into those that do, or do not, contain a click \n",
    "    #on a website for our archetype\n",
    "    with tqdm(total=len(sessions)) as pbar:\n",
    "        for session in sessions:\n",
    "            for query in session:\n",
    "                if query[4] in archSites:\n",
    "                    sterSessions.append(session)\n",
    "                    ster = True\n",
    "                    break\n",
    "            if arch == False:\n",
    "                notSterSessions.append(session)\n",
    "            else:\n",
    "                ster = False\n",
    "            pbar.update(1)\n",
    "   \n",
    "\n",
    "    pickle.dump( sterSessions, open( \"Pickles/SterPickles/Ster\"+ str(count) +\".p\", \"wb\" ) )\n",
    "    pickle.dump( notSterSessions, open( \"Pickles/NotSterPickles/NotSter\"+ str(count) +\".p\", \"wb\" ) )\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate Stereotype Sessions\n",
    "\n",
    "Opens all pickles that contain sessions with clicks on websites designated as for our Stereotype, and then further seperates them into sessions we label as generated by our Stereotype, and session that aren't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ster1 = np.asarray(pickle.load( open( \"Pickles/SterPickles/Ster1.p\", \"rb\" ) ), dtype=object)\n",
    "ster2 = np.asarray(pickle.load( open( \"Pickles/SterPickles/Ster2.p\", \"rb\" ) ), dtype=object)\n",
    "ster3 = np.asarray(pickle.load( open( \"Pickles/SterPickles/Ster3.p\", \"rb\" ) ), dtype=object)\n",
    "ster4 = np.asarray(pickle.load( open( \"Pickles/SterPickles/Ster4.p\", \"rb\" ) ), dtype=object)\n",
    "ster5 = np.asarray(pickle.load( open( \"Pickles/SterPickles/Ster5.p\", \"rb\" ) ), dtype=object)\n",
    "ster6 = np.asarray(pickle.load( open( \"Pickles/SterPickles/Ster6.p\", \"rb\" ) ), dtype=object)\n",
    "ster7 = np.asarray(pickle.load( open( \"Pickles/SterPickles/Ster7.p\", \"rb\" ) ), dtype=object)\n",
    "ster8 = np.asarray(pickle.load( open( \"Pickles/SterPickles/Ster8.p\", \"rb\" ) ), dtype=object)\n",
    "ster9 = np.asarray(pickle.load( open( \"Pickles/SterPickles/Ster9.p\", \"rb\" ) ), dtype=object)\n",
    "ster10 = np.asarray(pickle.load( open( \"Pickles/SterPickles/Ster0.p\", \"rb\" ) ), dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ster = np.concatenate((ster1, ster2, ster3, ster4, ster5, ster6, ster7, ster8, ster9, ster10), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes all sessions that have more than 200 hundred entries \n",
    "\n",
    "sterRefined = []\n",
    "for session in stype:\n",
    "    if len(session) < 200:\n",
    "        stypeRefined.append(session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( sterRefined, open( \"Pickles/stypePickles/stypeRefined.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefSter = [] # Sessions that exclusively click on sites designed for kids\n",
    "duraSter = [] # Sessions that click on a site for kids and have a session length of less than 6 minutes\n",
    "notSter = [] # Sessions that belong to neither of the previous two\n",
    "\n",
    "with tqdm(total=len(sterRefined)) as pbar:\n",
    "    for session in sterRefined:\n",
    "        clicks = 0\n",
    "        kClicks = 0\n",
    "        for query in session:\n",
    "            if query[4]:\n",
    "                clicks +=1\n",
    "                if query[4] in sterSites:\n",
    "                    kClicks +=1\n",
    "        if(kClicks/clicks == 1):\n",
    "            prefSter.append(session)\n",
    "        else:\n",
    "\n",
    "            startTime =  datetime.strptime(session[0][2], \"%Y-%m-%d %H:%M:%S\")\n",
    "            startTimeStamp = datetime.timestamp(startTime)\n",
    "            endTime = datetime.strptime(session[len(session)-1][2], \"%Y-%m-%d %H:%M:%S\")\n",
    "            endTimeStamp = datetime.timestamp(endTime)\n",
    "            if(endTimeStamp - startTimeStamp) < (60*6):\n",
    "                duraSter.append(session)\n",
    "            else:\n",
    "                notSter.append(session)\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prefSter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(duraSter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prefSter) + len(duraSter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( duraArch, open( \"Pickles/SterPickles/DuraSter.p\", \"wb\" ) )\n",
    "pickle.dump( prefArch, open( \"Pickles/SterPickles/PrefSter.p\", \"wb\" ) )\n",
    "pickle.dump( notArch, open( \"Pickles/NotSterPickles/NotSter10.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate all sessions that are not our Archetype\n",
    "\n",
    "This block of code concatenates all sessions that are labeled as not being to our Archetype, and removing all sessions that don't have any clicks from that set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notSter1 = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/NotSter1.p\", \"rb\" ), dtype=object ))\n",
    "notSter2 = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/NotSter2.p\", \"rb\" ), dtype=object ))\n",
    "notSter3 = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/NotSter3.p\", \"rb\" ), dtype=object ))\n",
    "notSter4 = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/NotSter4.p\", \"rb\" ), dtype=object ))\n",
    "notSter5 = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/NotSter5.p\", \"rb\" ), dtype=object ))\n",
    "notSter6 = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/NotSter6.p\", \"rb\" ), dtype=object ))\n",
    "notSter7 = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/NotSter7.p\", \"rb\" ), dtype=object ))\n",
    "notSter8 = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/NotSter8.p\", \"rb\" ), dtype=object ))\n",
    "notSter9 = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/NotSter9.p\", \"rb\" ), dtype=object ))\n",
    "notSter10 = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/NotSter0.p\", \"rb\" ), dtype=object ))\n",
    "notSter11 = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/NotSter10.p\", \"rb\" ), dtype=object ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notSter = np.concatenate((notSter, notSter2, notSter3,notSter4,notSter5,notSter6,notSter7,notSter8,notSter9,notSter10, notSter11), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all sessions with no clicks\n",
    "\n",
    "notSterClick = []\n",
    "with tqdm(total=len(notArch)) as pbar:\n",
    "    for session in notSter:\n",
    "        for query in session:\n",
    "            if query[3]:\n",
    "                #print(query)\n",
    "                notSterClick.append(session)\n",
    "                break\n",
    "            else:\n",
    "                pass\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process TREC\n",
    "\n",
    "This loads and processes the TREC session track query logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryLog = []\n",
    "with open('DataSources/TREC/sessiontrack2014.xml') as fd:\n",
    "    doc = xmltodict.parse(fd.read())\n",
    "for x in range(len(doc['sessiontrack2014']['session'])):\n",
    "    if type(doc['sessiontrack2014']['session'][x]['interaction']) is list:\n",
    "        for entry in (doc['sessiontrack2014']['session'][x]['interaction']):\n",
    "            #print(type(entry))\n",
    "            if not isinstance(entry, str):\n",
    "                queryLog.append([x, entry['query'], entry['@starttime'], '', ''])\n",
    "                if 'clicked' in entry.keys():\n",
    "                    if type(entry['clicked']['click']) is list: \n",
    "                        #print('list')\n",
    "                        for clicks in entry['clicked']['click']:\n",
    "                            #print(clicks['rank'])\n",
    "                            if int(clicks['rank'])-1 <10:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-1]['url']])\n",
    "                            elif int(clicks['rank'])-1 <20:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-11]['url']])\n",
    "                            elif int(clicks['rank'])-1 <30:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-21]['url']])\n",
    "                            elif int(clicks['rank'])-1 <40:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-31]['url']])\n",
    "                            elif int(clicks['rank'])-1 <50:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-41]['url']])\n",
    "                            elif int(clicks['rank'])-1 <60:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-51]['url']])\n",
    "                            elif int(clicks['rank'])-1 <70:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-61]['url']])\n",
    "                            else:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-71]['url']])\n",
    "                    else:\n",
    "                        if (int(entry['clicked']['click']['rank'])-1) < 10:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-1]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 20:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-11]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 30:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-21]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 40:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-31]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 50:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-41]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 60:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-51]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 70:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-61]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 80:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-71]['url']])\n",
    "                        else:  \n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-81]['url']])\n",
    "            else:\n",
    "                print(entry)\n",
    "    else:\n",
    "        queryLog.append([x, doc['sessiontrack2014']['session'][x]['interaction']['query'], doc['sessiontrack2014']['session'][x]['interaction']['@starttime'], '', ''])\n",
    "        if 'clicked' in doc['sessiontrack2014']['session'][x]['interaction'].keys():\n",
    "            if type(doc['sessiontrack2014']['session'][x]['interaction']['clicked']['click']) is list: \n",
    "                for clicks in doc['sessiontrack2014']['session'][x]['interaction']['clicked']['click']:\n",
    "                    queryLog.append([x, doc['sessiontrack2014']['session'][x]['interaction']['query'], clicks['@starttime'], clicks['rank'], doc['sessiontrack2014']['session'][x]['interaction']['results']['result'][int(clicks['rank'])-1]['url']]) \n",
    "                pass\n",
    "            else:\n",
    "                queryLog.append([x, doc['sessiontrack2014']['session'][x]['interaction']['query'], doc['sessiontrack2014']['session'][x]['interaction']['clicked']['click']['@starttime'], doc['sessiontrack2014']['session'][x]['interaction']['clicked']['click']['rank'], doc['sessiontrack2014']['session'][x]['interaction']['results']['result'][int(doc['sessiontrack2014']['session'][x]['interaction']['clicked']['click']['rank'])-1]['url']])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DataSources/TREC/sessiontrack2013.xml') as fd:\n",
    "    doc = xmltodict.parse(fd.read())\n",
    "for x in range(len(doc['sessiontrack2013']['session'])):\n",
    "    #print(type(doc['sessiontrack2014']['session'][x]['interaction']))\n",
    "    if type(doc['sessiontrack2013']['session'][x]['interaction']) is list:\n",
    "        for entry in (doc['sessiontrack2013']['session'][x]['interaction']):\n",
    "            #print(type(entry))\n",
    "            if not isinstance(entry, str):\n",
    "                queryLog.append([x, entry['query'], entry['@starttime'], '', ''])\n",
    "                if 'clicked' in entry.keys():\n",
    "                    if type(entry['clicked']['click']) is list: \n",
    "                        #print('list')\n",
    "                        for clicks in entry['clicked']['click']:\n",
    "                            #print(clicks['rank'])\n",
    "                            if int(clicks['rank'])-1 <10:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-1]['url']])\n",
    "                            elif int(clicks['rank'])-1 <20:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-11]['url']])\n",
    "                            elif int(clicks['rank'])-1 <30:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-21]['url']])\n",
    "                            elif int(clicks['rank'])-1 <40:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-31]['url']])\n",
    "                            elif int(clicks['rank'])-1 <50:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-41]['url']])\n",
    "                            elif int(clicks['rank'])-1 <60:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-51]['url']])\n",
    "                            elif int(clicks['rank'])-1 <70:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-61]['url']])\n",
    "                            else:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-71]['url']])\n",
    "                    else:\n",
    "                        #print(int(entry['clicked']['click']['rank'])-1)\n",
    "                        if (int(entry['clicked']['click']['rank'])-1) < 10:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-1]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 20:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-11]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 30:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-21]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 40:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-31]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 50:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-41]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 60:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-51]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 70:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-61]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 80:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-71]['url']])\n",
    "                        else:  \n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-81]['url']])\n",
    "            else:\n",
    "                queryLog.append(entry)\n",
    "    else:\n",
    "        queryLog.append([x, doc['sessiontrack2013']['session'][x]['interaction']['query'], doc['sessiontrack2013']['session'][x]['interaction']['@starttime'], '', ''])\n",
    "        if 'clicked' in doc['sessiontrack2013']['session'][x]['interaction'].keys():\n",
    "            if type(doc['sessiontrack2013']['session'][x]['interaction']['clicked']['click']) is list: \n",
    "                for clicks in doc['sessiontrack2013']['session'][x]['interaction']['clicked']['click']:\n",
    "                    queryLog.append([x, doc['sessiontrack2013']['session'][x]['interaction']['query'], clicks['@starttime'], clicks['rank'], doc['sessiontrack2013']['session'][x]['interaction']['results']['result'][int(clicks['rank'])-1]['url']]) \n",
    "                pass\n",
    "            else:\n",
    "                queryLog.append([x, doc['sessiontrack2013']['session'][x]['interaction']['query'], doc['sessiontrack2013']['session'][x]['interaction']['clicked']['click']['@starttime'], doc['sessiontrack2013']['session'][x]['interaction']['clicked']['click']['rank'], doc['sessiontrack2013']['session'][x]['interaction']['results']['result'][int(doc['sessiontrack2013']['session'][x]['interaction']['clicked']['click']['rank'])-1]['url']])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DataSources/TREC/sessiontrack2012.xml') as fd:\n",
    "    doc = xmltodict.parse(fd.read())\n",
    "for x in range(len(doc['sessiontrack2012']['session'])):\n",
    "    if type(doc['sessiontrack2012']['session'][x]['interaction']) is list:\n",
    "        for entry in (doc['sessiontrack2012']['session'][x]['interaction']):\n",
    "            #print(type(entry))\n",
    "            if not isinstance(entry, str):\n",
    "                queryLog.append([x, entry['query'], entry['@starttime'], '', ''])\n",
    "                \n",
    "                if 'clicked' in entry.keys():\n",
    "                    if type(entry['clicked']) is None:\n",
    "                        break\n",
    "                    if type(entry['clicked']['click']) is list: \n",
    "                        #print('list')\n",
    "                        for clicks in entry['clicked']['click']:\n",
    "                            #print(clicks['rank'])\n",
    "                            if int(clicks['rank'])-1 <10:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-1]['url']])\n",
    "                            elif int(clicks['rank'])-1 <20:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-11]['url']])\n",
    "                            elif int(clicks['rank'])-1 <30:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-21]['url']])\n",
    "                            elif int(clicks['rank'])-1 <40:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-31]['url']])\n",
    "                            elif int(clicks['rank'])-1 <50:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-41]['url']])\n",
    "                            elif int(clicks['rank'])-1 <60:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-51]['url']])\n",
    "                            elif int(clicks['rank'])-1 <70:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-61]['url']])\n",
    "                            else:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-71]['url']])\n",
    "                    else:\n",
    "                        #print(int(entry['clicked']['click']['rank'])-1)\n",
    "                        if (int(entry['clicked']['click']['rank'])-1) < 10:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-1]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 20:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-11]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 30:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-21]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 40:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-31]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 50:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-41]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 60:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-51]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 70:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-61]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 80:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-71]['url']])\n",
    "                        else:  \n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-81]['url']])\n",
    "            else:\n",
    "                print(entry)\n",
    "    else:\n",
    "        queryLog.append([x, doc['sessiontrack2012']['session'][x]['interaction']['query'], doc['sessiontrack2012']['session'][x]['interaction']['@starttime'], '', ''])\n",
    "        if 'clicked' in doc['sessiontrack2012']['session'][x]['interaction'].keys():\n",
    "            if type(doc['sessiontrack2012']['session'][x]['interaction']['clicked']['click']) is list: \n",
    "                for clicks in doc['sessiontrack2012']['session'][x]['interaction']['clicked']['click']:\n",
    "                    queryLog.append([x, doc['sessiontrack2012']['session'][x]['interaction']['query'], clicks['@starttime'], clicks['rank'], doc['sessiontrack2012']['session'][x]['interaction']['results']['result'][int(clicks['rank'])-1]['url']]) \n",
    "                pass\n",
    "            else:\n",
    "                queryLog.append([x, doc['sessiontrack2012']['session'][x]['interaction']['query'], doc['sessiontrack2012']['session'][x]['interaction']['clicked']['click']['@starttime'], doc['sessiontrack2012']['session'][x]['interaction']['clicked']['click']['rank'], doc['sessiontrack2012']['session'][x]['interaction']['results']['result'][int(doc['sessiontrack2012']['session'][x]['interaction']['clicked']['click']['rank'])-1]['url']])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DataSources/TREC/sessiontrack2011.xml') as fd:\n",
    "    doc = xmltodict.parse(fd.read())\n",
    "for x in range(len(doc['sessiontrack2011']['session'])):\n",
    "    #print(type(doc['sessiontrack2014']['session'][x]['interaction']))\n",
    "    if type(doc['sessiontrack2011']['session'][x]['interaction']) is list:\n",
    "        for entry in (doc['sessiontrack2011']['session'][x]['interaction']):\n",
    "            #print(type(entry))\n",
    "            if not isinstance(entry, str):\n",
    "                queryLog.append([x, entry['query'], entry['@starttime'], '', ''])\n",
    "                \n",
    "                if 'clicked' in entry.keys():\n",
    "                    if type(entry['clicked']) is None:\n",
    "                        break\n",
    "                    if type(entry['clicked']['click']) is list: \n",
    "                        #print('list')\n",
    "                        for clicks in entry['clicked']['click']:\n",
    "                            #print(clicks['rank'])\n",
    "                            if int(clicks['rank'])-1 <10:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-1]['url']])\n",
    "                            elif int(clicks['rank'])-1 <20:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-11]['url']])\n",
    "                            elif int(clicks['rank'])-1 <30:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-21]['url']])\n",
    "                            elif int(clicks['rank'])-1 <40:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-31]['url']])\n",
    "                            elif int(clicks['rank'])-1 <50:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-41]['url']])\n",
    "                            elif int(clicks['rank'])-1 <60:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-51]['url']])\n",
    "                            elif int(clicks['rank'])-1 <70:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-61]['url']])\n",
    "                            else:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-71]['url']])\n",
    "                    else:\n",
    "                        #print(int(entry['clicked']['click']['rank'])-1)\n",
    "                        if (int(entry['clicked']['click']['rank'])-1) < 10:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-1]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 20:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-11]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 30:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-21]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 40:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-31]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 50:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-41]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 60:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-51]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 70:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-61]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 80:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-71]['url']])\n",
    "                        else:  \n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-81]['url']])\n",
    "            else:\n",
    "                print(entry)\n",
    "    else:\n",
    "        queryLog.append([x, doc['sessiontrack2011']['session'][x]['interaction']['query'], doc['sessiontrack2011']['session'][x]['interaction']['@starttime'], '', ''])\n",
    "        if 'clicked' in doc['sessiontrack2011']['session'][x]['interaction'].keys():\n",
    "            if type(doc['sessiontrack2011']['session'][x]['interaction']['clicked']['click']) is list: \n",
    "                for clicks in doc['sessiontrack2011']['session'][x]['interaction']['clicked']['click']:\n",
    "                    queryLog.append([x, doc['sessiontrack2011']['session'][x]['interaction']['query'], clicks['@starttime'], clicks['rank'], doc['sessiontrack2011']['session'][x]['interaction']['results']['result'][int(clicks['rank'])-1]['url']]) \n",
    "                pass\n",
    "            else:\n",
    "                queryLog.append([x, doc['sessiontrack2011']['session'][x]['interaction']['query'], doc['sessiontrack2011']['session'][x]['interaction']['clicked']['click']['@starttime'], doc['sessiontrack2011']['session'][x]['interaction']['clicked']['click']['rank'], doc['sessiontrack2011']['session'][x]['interaction']['results']['result'][int(doc['sessiontrack2011']['session'][x]['interaction']['clicked']['click']['rank'])-1]['url']])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentUser = queryLog[0][0]\n",
    "sessions = []\n",
    "session = []\n",
    "for row in queryLog:\n",
    "    tempUser = row[0]\n",
    "    if(tempUser != currentUser):\n",
    "        sessions.append(session)\n",
    "        session = []\n",
    "        currentUser = tempUser\n",
    "    session.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( sessions, open( \"Pickles/NotSterPickles/TRECS.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRECS = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/TRECS.p\", \"rb\" ) ), dtype = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TRECS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess timestamp on TREC sessions to match AOL logs\n",
    "\n",
    "for session in TRECS:\n",
    "    if '.'  in session[0][2][0]:\n",
    "        initialTimeStamp = session[0][2].split('.')[0]\n",
    "        date = datetime.strptime(initialTimeStamp, \"%H:%M:%S\")\n",
    "        tempTime = datetime.timestamp(date)\n",
    "        for query in session:\n",
    "            date2 = datetime.strptime(query[2].split('.')[0], \"%H:%M:%S\")\n",
    "            tempTime2 = datetime.timestamp(date2)   \n",
    "            query[2] = tempTime2 - tempTime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TRECS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only add sessions that have a click\n",
    "\n",
    "newTRECS = []\n",
    "count = 0\n",
    "for session in TRECS:\n",
    "    for query in session:\n",
    "        if query[3]:\n",
    "            newTRECS.append(session)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRECS = newTRECS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TRECS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Sessions With Clicks\n",
    "\n",
    "Creates the Sessions With Clicks data set by combining sessions from TREC, as well as those we labeled as belonging to users who are, and are not; our Stereotype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duraSter = np.asarray(pickle.load( open( \"Pickles/SterPickles/duraSter.p\", \"rb\" ) ))\n",
    "prefSter = np.asarray(pickle.load( open( \"Pickles/SterPickles/prefSter.p\", \"rb\" ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomNotSter = np.random.choice(notSterClick, size=(((len(duraSter) + len(prefSter))*4)-len(TRECS)), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in randomNotSter:\n",
    "    date = datetime.strptime(session[0][2], \"%Y-%m-%d %H:%M:%S\")\n",
    "    tempTime = datetime.timestamp(date)\n",
    "    for query in session:\n",
    "        date2 = datetime.strptime(query[2], \"%Y-%m-%d %H:%M:%S\")\n",
    "        tempTime2 = datetime.timestamp(date2)   \n",
    "        query[2] = tempTime2 - tempTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notArchComplete =  np.concatenate((randomNotSter, TRECS), axis=0, dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(notSterComplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sterComplete = np.concatenate((duraArch, prefArch), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in sterComplete:\n",
    "    date = datetime.strptime(session[0][2], \"%Y-%m-%d %H:%M:%S\")\n",
    "    tempTime = datetime.timestamp(date)\n",
    "    for query in session:\n",
    "        date2 = datetime.strptime(query[2], \"%Y-%m-%d %H:%M:%S\")\n",
    "        tempTime2 = datetime.timestamp(date2)   \n",
    "        query[2] = tempTime2 - tempTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sterComplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( sterComplete, open( \"DataSets/SWC/SterComplete.p\", \"wb\" ) )\n",
    "pickle.dump( notSterComplete, open( \"DataSets/SWC/NotSterComplete.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Query Data Set\n",
    "\n",
    "Creates the Single Query data set from the Sven data source and extracing single queries from the TREC sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "kidsQ = []\n",
    "with open('DataSources/Sven/ChildrenQueries.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        kidsQ.append(row[0][:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRECQ = []\n",
    "for session in TRECS:\n",
    "    for query in session:\n",
    "        TRECQ.append(query[1])\n",
    "TRECQ = list(set(TRECQ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRECQSelected = np.random.choice(TRECQ, size=(len(kidsQ)*4), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TRECQSelected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( TRECQSelected, open( \"DataSets/SQS/SQSNS.p\", \"wb\" ) )\n",
    "pickle.dump( kidsQ, open( \"DataSets/SQS/SQSS.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Preprocessing\n",
    "\n",
    "There is an issue with how clicks and queries are represented in the AOL query logs, the following steps clearly seperates the two allowing for experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sterComplete = pickle.load( open( \"DataSets/SWC/SterComplete.p\", \"rb\" ) )\n",
    "notSterComplete = pickle.load( open( \"DataSets/SWC/NotSterComplete.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sterCompleteProc = splitQueryClicksAOL(sterComplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notSterCompleteProc = np.concatenate((splitQueryClicksAOL(notSterComplete[:(len(notSterComplete)-len(TRECS))]), splitQueryClicksTREC(notArchComplete[(len(notSterComplete)-len(TRECS)):])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( sterCompleteProc, open( \"DataSets/SWC/SWCS.p\", \"wb\" ) )\n",
    "pickle.dump( notSterCompleteProc, open( \"DataSets/SWC/SWCNS.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Preprocessing Pt. 2\n",
    "\n",
    "These next steps remove some bad queries, as the AOL query logs replace some queries with '-'. Further more, some punctuation is represented in it's ascii format. We replace that too. If this causes the session to contain no clicks, we remove that session; as one of our ground rules for these kind of sessions is they must contain one click. Furthermore, we convert all sessions into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ster = pickle.load( open( \"DataSets/SWC/SWCS.p\", \"rb\" ) )\n",
    "notSter = pickle.load( open( \"DataSets/SWC/SWCNS.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newSter = []\n",
    "count = 0\n",
    "sterQL = []\n",
    "pattern = ' 20[^0-9. ]'\n",
    "with tqdm(total = len(arch) ) as pbar:\n",
    "    for session in ster:\n",
    "        order = 0\n",
    "        for query in session:\n",
    "            if query[1] == '-':\n",
    "                 pass\n",
    "            else:\n",
    "                if ' 20' in query[1]:\n",
    "                    result = re.search(pattern, query[1])\n",
    "                    if result:\n",
    "                        query[1]= re.sub(' 20', \" \", query[1])\n",
    "                        #print(query)\n",
    "                query[0] = count\n",
    "                query.append(order)\n",
    "                sterQL.append(query)\n",
    "                order += 1\n",
    "        count +=1\n",
    "        pbar.update()\n",
    "sterPD = pd.DataFrame(sterQL, columns = [\"sID\", \"query\", \"timestamp\",\"click\",\"website\",\"type\",\"order\"] )  \n",
    "sterPD['class'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notSterQL = []\n",
    "for session in notSter:\n",
    "    order = 0\n",
    "    for query in session:\n",
    "        if query[1] == '-':\n",
    "            pass\n",
    "        else:\n",
    "            if ' 20' in query[1]:\n",
    "                result = re.search(pattern, query[1])\n",
    "                if result:\n",
    "                    query[1]= re.sub(' 20', \" \", query[1])\n",
    "            query[0] = count\n",
    "            query.append(order)\n",
    "            notSterQL.append(query)\n",
    "            order += 1\n",
    "    count +=1\n",
    "notSterPD = pd.DataFrame(notSterQL, columns = [\"sID\", \"query\", \"timestamp\",\"click\",\"website\",\"type\",\"order\"] )  \n",
    "notSterPD['class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allSessions = pd.concat([sterPD, notSterPD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toKeep = (allSessions.groupby('sID')['type'].nunique()==2) ##checks to see if a session has both a Click and a Query\n",
    "toKeep = pd.DataFrame(toKeep)\n",
    "toKeep = toKeep[toKeep['type']==True].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allSessions = allSessions[allSessions['sID'].isin(toKeep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allSessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(allSessions, open( \"DataSets/SWC/SWC.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
