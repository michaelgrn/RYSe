{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "import xmltodict\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DMOZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kids_sites = []\n",
    "with open('DataSources/DMOZ/URL Classification.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "        for row in csv_reader:\n",
    "            if(row[2] == 'Kids'):\n",
    "                kids_sites.append(row[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Process AOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1026700/1026700 [47:24<00:00, 360.96it/s] \n",
      "100%|██████████| 1048214/1048214 [39:24<00:00, 443.31it/s] \n",
      "100%|██████████| 1035512/1035512 [4:52:13<00:00, 59.06it/s]    \n",
      "100%|██████████| 1027945/1027945 [48:27<00:00, 353.51it/s] \n",
      "100%|██████████| 1042955/1042955 [41:28<00:00, 419.08it/s] \n",
      "100%|██████████| 1020676/1020676 [37:06<00:00, 458.42it/s] \n",
      "100%|██████████| 1046064/1046064 [36:36<00:00, 476.28it/s] \n",
      "100%|██████████| 1030754/1030754 [36:13<00:00, 474.17it/s] \n",
      "100%|██████████| 1031535/1031535 [36:20<00:00, 473.16it/s] \n",
      "100%|██████████| 1031302/1031302 [36:23<00:00, 472.24it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "count = 0\n",
    "for filename in glob.glob(\"DataSources/AOL/*.txt\"):\n",
    "    query_log = []\n",
    "    with open(filename) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter = '\\t')\n",
    "        linecount = 0\n",
    "        for row in csv_reader:\n",
    "            if(linecount > 0):\n",
    "                query_log.append(row)\n",
    "            linecount += 1\n",
    "    \n",
    "    currentUser = query_log[0][0]\n",
    "    date = datetime.strptime(query_log[0][2], \"%Y-%m-%d %H:%M:%S\")\n",
    "    currentTime = datetime.timestamp(date)\n",
    "\n",
    "    sessions = []\n",
    "    session = []\n",
    "    \n",
    "    for row in query_log:\n",
    "        tempUser = row[0]\n",
    "        date = datetime.strptime(row[2], \"%Y-%m-%d %H:%M:%S\")\n",
    "        tempTime = datetime.timestamp(date)\n",
    "        if(tempUser != currentUser):\n",
    "            sessions.append(session)\n",
    "            session = []\n",
    "            currentUser = tempUser\n",
    "            date = datetime.strptime(row[2], \"%Y-%m-%d %H:%M:%S\")\n",
    "            tempTime = datetime.timestamp(date)\n",
    "            currentTime = tempTime\n",
    "        if(tempTime > (currentTime + (60*60))):\n",
    "            sessions.append(session)\n",
    "            session = []\n",
    "            currentTime = tempTime\n",
    "        session.append(row)\n",
    "  \n",
    "    from tqdm import tqdm\n",
    "    kidsSessions = []\n",
    "    notArchSessions = []\n",
    "    kids = False\n",
    "    with tqdm(total=len(sessions)) as pbar:\n",
    "        for session in sessions:\n",
    "            for query in session:\n",
    "                if query[4] in kids_sites:\n",
    "                    kidsSessions.append(session)\n",
    "                    kids = True\n",
    "                    break\n",
    "            if kids == False:\n",
    "                notArchSessions.append(session)\n",
    "            else:\n",
    "                kids = False\n",
    "            pbar.update(1)\n",
    "   \n",
    "\n",
    "    pickle.dump( kidsSessions, open( \"Pickles/ArchPickles/Arch\"+ str(count) +\".p\", \"wb\" ) )\n",
    "    pickle.dump( notArchSessions, open( \"Pickles/NotArchPickles/NotArch\"+ str(count) +\".p\", \"wb\" ) )\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cocatenate Archetype Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bl4z3/miniconda3/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "arch1 = np.asarray(pickle.load( open( \"Pickles/ArchPickles/Arch1.p\", \"rb\" ) ))\n",
    "arch2 = np.asarray(pickle.load( open( \"Pickles/ArchPickles/Arch2.p\", \"rb\" ) ))\n",
    "arch3 = np.asarray(pickle.load( open( \"Pickles/ArchPickles/Arch3.p\", \"rb\" ) ))\n",
    "arch4 = np.asarray(pickle.load( open( \"Pickles/ArchPickles/Arch4.p\", \"rb\" ) ))\n",
    "arch5 = np.asarray(pickle.load( open( \"Pickles/ArchPickles/Arch5.p\", \"rb\" ) ))\n",
    "arch6 = np.asarray(pickle.load( open( \"Pickles/ArchPickles/Arch6.p\", \"rb\" ) ))\n",
    "arch7 = np.asarray(pickle.load( open( \"Pickles/ArchPickles/Arch7.p\", \"rb\" ) ))\n",
    "arch8 = np.asarray(pickle.load( open( \"Pickles/ArchPickles/Arch8.p\", \"rb\" ) ))\n",
    "arch9 = np.asarray(pickle.load( open( \"Pickles/ArchPickles/Arch9.p\", \"rb\" ) ))\n",
    "arch10 = np.asarray(pickle.load( open( \"Pickles/ArchPickles/Arch0.p\", \"rb\" ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = np.concatenate((arch1, arch2, arch3, arch4, arch5, arch6, arch7, arch8, arch9, arch10), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7574\n",
      "7575\n",
      "7576\n",
      "7577\n",
      "7578\n",
      "7579\n",
      "7580\n",
      "7581\n",
      "7582\n",
      "7583\n",
      "7584\n",
      "7585\n",
      "7586\n",
      "7587\n",
      "7588\n",
      "7589\n",
      "7590\n",
      "7591\n",
      "7592\n",
      "7593\n",
      "7594\n",
      "7595\n",
      "7596\n",
      "7597\n",
      "7598\n",
      "7599\n",
      "7600\n",
      "7601\n",
      "7602\n",
      "7603\n",
      "7604\n",
      "7605\n",
      "7606\n",
      "7607\n",
      "7608\n",
      "7609\n",
      "7610\n",
      "7611\n",
      "7612\n",
      "7613\n",
      "7614\n",
      "7615\n",
      "7616\n",
      "7617\n",
      "7618\n",
      "7619\n",
      "7620\n",
      "7621\n",
      "7622\n",
      "7623\n",
      "7624\n",
      "7625\n",
      "7626\n",
      "7627\n",
      "7628\n",
      "7629\n",
      "7630\n",
      "7631\n",
      "7632\n",
      "7633\n",
      "7634\n",
      "7635\n",
      "7636\n",
      "7637\n",
      "7638\n",
      "7639\n",
      "7640\n",
      "7641\n",
      "7642\n",
      "7643\n",
      "7644\n",
      "7645\n",
      "7646\n",
      "7647\n",
      "7648\n",
      "7649\n",
      "7650\n",
      "7651\n",
      "7652\n",
      "7653\n",
      "7654\n"
     ]
    }
   ],
   "source": [
    "#Removes all sessions that have more than 200 hundred entries \n",
    "\n",
    "count = 0\n",
    "archRefined = []\n",
    "for session in arch:\n",
    "    if len(session) > 200:\n",
    "        print(count)\n",
    "    else:\n",
    "        archRefined.append(session)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( archRefined, open( \"Pickles/ArchPickles/ArchRefined.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19139/19139 [01:10<00:00, 270.57it/s]\n"
     ]
    }
   ],
   "source": [
    "prefArch = [] # Sessions that exclusively click on sites designed for kids\n",
    "duraArch = [] # Sessions that click on a site for kids and have a session length of less than 6 minutes\n",
    "notArch = [] # Sessionst that belong to neither of the previous two\n",
    "\n",
    "with tqdm(total=len(archRefined)) as pbar:\n",
    "    for session in archRefined:\n",
    "        clicks = 0\n",
    "        kClicks = 0\n",
    "        for query in session:\n",
    "            if query[4]:\n",
    "                clicks +=1\n",
    "                if query[4] in kids_sites:\n",
    "                    kClicks +=1\n",
    "        if(kClicks/clicks == 1):\n",
    "            prefArch.append(session)\n",
    "        else:\n",
    "\n",
    "            startTime =  datetime.strptime(session[0][2], \"%Y-%m-%d %H:%M:%S\")\n",
    "            startTimeStamp = datetime.timestamp(startTime)\n",
    "            endTime = datetime.strptime(session[len(session)-1][2], \"%Y-%m-%d %H:%M:%S\")\n",
    "            endTimeStamp = datetime.timestamp(endTime)\n",
    "            if(endTimeStamp - startTimeStamp) < (60*6):\n",
    "                duraArch.append(session)\n",
    "            else:\n",
    "                notArch.append(session)\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4721"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prefArch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3259"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(duraArch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7980"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(duraArch) + len(prefArch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( duraArch, open( \"Pickles/ArchPickles/DuraArch.p\", \"wb\" ) )\n",
    "pickle.dump( prefArch, open( \"Pickles/ArchPickles/PrefArch.p\", \"wb\" ) )\n",
    "pickle.dump( notArch, open( \"Pickles/NotArchPickles/NotArch10.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate all sessions that are not our Archetype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "notArch1 = np.asarray(pickle.load( open( \"Pickles/NotArchPickles/NotArch1.p\", \"rb\" ) ))\n",
    "notArch2 = np.asarray(pickle.load( open( \"Pickles/NotArchPickles/NotArch2.p\", \"rb\" ) ))\n",
    "notArch3 = np.asarray(pickle.load( open( \"Pickles/NotArchPickles/NotArch3.p\", \"rb\" ) ))\n",
    "notArch4 = np.asarray(pickle.load( open( \"Pickles/NotArchPickles/NotArch4.p\", \"rb\" ) ))\n",
    "notArch5 = np.asarray(pickle.load( open( \"Pickles/NotArchPickles/NotArch5.p\", \"rb\" ) ))\n",
    "notArch6 = np.asarray(pickle.load( open( \"Pickles/NotArchPickles/NotArch6.p\", \"rb\" ) ))\n",
    "notArch7 = np.asarray(pickle.load( open( \"Pickles/NotArchPickles/NotArch7.p\", \"rb\" ) ))\n",
    "notArch8 = np.asarray(pickle.load( open( \"Pickles/NotArchPickles/NotArch8.p\", \"rb\" ) ))\n",
    "notArch9 = np.asarray(pickle.load( open( \"Pickles/NotArchPickles/NotArch9.p\", \"rb\" ) ))\n",
    "notArch10 = np.asarray(pickle.load( open( \"Pickles/NotArchPickles/NotArch0.p\", \"rb\" ) ))\n",
    "notArch11 = np.asarray(pickle.load( open( \"Pickles/NotArchPickles/notArch10.p\", \"rb\" ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "notArch = np.concatenate((notArch1, notArch2, notArch3,notArch4,notArch5,notArch6,notArch7,notArch8,notArch9,notArch10, notArch11), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10333596/10333596 [00:55<00:00, 187645.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# Remove all sessions with no clicks\n",
    "\n",
    "notArchClick = []\n",
    "with tqdm(total=len(notArch)) as pbar:\n",
    "    for session in notArch:\n",
    "        for query in session:\n",
    "            if query[3]:\n",
    "                #print(query)\n",
    "                notArchClick.append(session)\n",
    "                break\n",
    "            else:\n",
    "                pass\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process TREC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryLog = []\n",
    "with open('DataSources/TREC/sessiontrack2014.xml') as fd:\n",
    "    doc = xmltodict.parse(fd.read())\n",
    "for x in range(1254):\n",
    "    #print(type(doc['sessiontrack2014']['session'][x]['interaction']))\n",
    "    if type(doc['sessiontrack2014']['session'][x]['interaction']) is list:\n",
    "        for entry in (doc['sessiontrack2014']['session'][x]['interaction']):\n",
    "            #print(type(entry))\n",
    "            if not isinstance(entry, str):\n",
    "                queryLog.append([x, entry['query'], entry['@starttime'], '', ''])\n",
    "                if 'clicked' in entry.keys():\n",
    "                    if type(entry['clicked']['click']) is list: \n",
    "                        #print('list')\n",
    "                        for clicks in entry['clicked']['click']:\n",
    "                            #print(clicks['rank'])\n",
    "                            if int(clicks['rank'])-1 <10:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-1]['url']])\n",
    "                            elif int(clicks['rank'])-1 <20:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-11]['url']])\n",
    "                            elif int(clicks['rank'])-1 <30:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-21]['url']])\n",
    "                            elif int(clicks['rank'])-1 <40:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-31]['url']])\n",
    "                            elif int(clicks['rank'])-1 <50:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-41]['url']])\n",
    "                            elif int(clicks['rank'])-1 <60:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-51]['url']])\n",
    "                            elif int(clicks['rank'])-1 <70:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-61]['url']])\n",
    "                            else:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-71]['url']])\n",
    "                    else:\n",
    "                        if (int(entry['clicked']['click']['rank'])-1) < 10:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-1]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 20:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-11]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 30:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-21]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 40:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-31]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 50:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-41]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 60:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-51]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 70:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-61]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 80:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-71]['url']])\n",
    "                        else:  \n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-81]['url']])\n",
    "            else:\n",
    "                print(entry)\n",
    "    else:\n",
    "        queryLog.append([x, doc['sessiontrack2014']['session'][x]['interaction']['query'], doc['sessiontrack2014']['session'][x]['interaction']['@starttime'], '', ''])\n",
    "        if 'clicked' in doc['sessiontrack2014']['session'][x]['interaction'].keys():\n",
    "            if type(doc['sessiontrack2014']['session'][x]['interaction']['clicked']['click']) is list: \n",
    "                for clicks in doc['sessiontrack2014']['session'][x]['interaction']['clicked']['click']:\n",
    "                    queryLog.append([x, doc['sessiontrack2014']['session'][x]['interaction']['query'], clicks['@starttime'], clicks['rank'], doc['sessiontrack2014']['session'][x]['interaction']['results']['result'][int(clicks['rank'])-1]['url']]) \n",
    "                pass\n",
    "            else:\n",
    "                queryLog.append([x, doc['sessiontrack2014']['session'][x]['interaction']['query'], doc['sessiontrack2014']['session'][x]['interaction']['clicked']['click']['@starttime'], doc['sessiontrack2014']['session'][x]['interaction']['clicked']['click']['rank'], doc['sessiontrack2014']['session'][x]['interaction']['results']['result'][int(doc['sessiontrack2014']['session'][x]['interaction']['clicked']['click']['rank'])-1]['url']])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DataSources/TREC/sessiontrack2013.xml') as fd:\n",
    "    doc = xmltodict.parse(fd.read())\n",
    "for x in range(132):\n",
    "    #print(type(doc['sessiontrack2014']['session'][x]['interaction']))\n",
    "    if type(doc['sessiontrack2013']['session'][x]['interaction']) is list:\n",
    "        for entry in (doc['sessiontrack2013']['session'][x]['interaction']):\n",
    "            #print(type(entry))\n",
    "            if not isinstance(entry, str):\n",
    "                queryLog.append([x, entry['query'], entry['@starttime'], '', ''])\n",
    "                if 'clicked' in entry.keys():\n",
    "                    if type(entry['clicked']['click']) is list: \n",
    "                        #print('list')\n",
    "                        for clicks in entry['clicked']['click']:\n",
    "                            #print(clicks['rank'])\n",
    "                            if int(clicks['rank'])-1 <10:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-1]['url']])\n",
    "                            elif int(clicks['rank'])-1 <20:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-11]['url']])\n",
    "                            elif int(clicks['rank'])-1 <30:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-21]['url']])\n",
    "                            elif int(clicks['rank'])-1 <40:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-31]['url']])\n",
    "                            elif int(clicks['rank'])-1 <50:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-41]['url']])\n",
    "                            elif int(clicks['rank'])-1 <60:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-51]['url']])\n",
    "                            elif int(clicks['rank'])-1 <70:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-61]['url']])\n",
    "                            else:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-71]['url']])\n",
    "                    else:\n",
    "                        #print(int(entry['clicked']['click']['rank'])-1)\n",
    "                        if (int(entry['clicked']['click']['rank'])-1) < 10:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-1]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 20:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-11]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 30:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-21]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 40:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-31]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 50:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-41]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 60:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-51]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 70:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-61]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 80:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-71]['url']])\n",
    "                        else:  \n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-81]['url']])\n",
    "            else:\n",
    "                queryLog.append(entry)\n",
    "    else:\n",
    "        queryLog.append([x, doc['sessiontrack2013']['session'][x]['interaction']['query'], doc['sessiontrack2013']['session'][x]['interaction']['@starttime'], '', ''])\n",
    "        if 'clicked' in doc['sessiontrack2013']['session'][x]['interaction'].keys():\n",
    "            if type(doc['sessiontrack2013']['session'][x]['interaction']['clicked']['click']) is list: \n",
    "                for clicks in doc['sessiontrack2013']['session'][x]['interaction']['clicked']['click']:\n",
    "                    queryLog.append([x, doc['sessiontrack2013']['session'][x]['interaction']['query'], clicks['@starttime'], clicks['rank'], doc['sessiontrack2013']['session'][x]['interaction']['results']['result'][int(clicks['rank'])-1]['url']]) \n",
    "                pass\n",
    "            else:\n",
    "                queryLog.append([x, doc['sessiontrack2013']['session'][x]['interaction']['query'], doc['sessiontrack2013']['session'][x]['interaction']['clicked']['click']['@starttime'], doc['sessiontrack2013']['session'][x]['interaction']['clicked']['click']['rank'], doc['sessiontrack2013']['session'][x]['interaction']['results']['result'][int(doc['sessiontrack2013']['session'][x]['interaction']['clicked']['click']['rank'])-1]['url']])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DataSources/TREC/sessiontrack2012.xml') as fd:\n",
    "    doc = xmltodict.parse(fd.read())\n",
    "for x in range(97):\n",
    "    #print(type(doc['sessiontrack2014']['session'][x]['interaction']))\n",
    "    if type(doc['sessiontrack2012']['session'][x]['interaction']) is list:\n",
    "        for entry in (doc['sessiontrack2012']['session'][x]['interaction']):\n",
    "            #print(type(entry))\n",
    "            if not isinstance(entry, str):\n",
    "                queryLog.append([x, entry['query'], entry['@starttime'], '', ''])\n",
    "                \n",
    "                if 'clicked' in entry.keys():\n",
    "                    if type(entry['clicked']) is None:\n",
    "                        break\n",
    "                    if type(entry['clicked']['click']) is list: \n",
    "                        #print('list')\n",
    "                        for clicks in entry['clicked']['click']:\n",
    "                            #print(clicks['rank'])\n",
    "                            if int(clicks['rank'])-1 <10:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-1]['url']])\n",
    "                            elif int(clicks['rank'])-1 <20:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-11]['url']])\n",
    "                            elif int(clicks['rank'])-1 <30:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-21]['url']])\n",
    "                            elif int(clicks['rank'])-1 <40:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-31]['url']])\n",
    "                            elif int(clicks['rank'])-1 <50:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-41]['url']])\n",
    "                            elif int(clicks['rank'])-1 <60:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-51]['url']])\n",
    "                            elif int(clicks['rank'])-1 <70:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-61]['url']])\n",
    "                            else:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-71]['url']])\n",
    "                    else:\n",
    "                        #print(int(entry['clicked']['click']['rank'])-1)\n",
    "                        if (int(entry['clicked']['click']['rank'])-1) < 10:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-1]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 20:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-11]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 30:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-21]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 40:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-31]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 50:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-41]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 60:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-51]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 70:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-61]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 80:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-71]['url']])\n",
    "                        else:  \n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-81]['url']])\n",
    "            else:\n",
    "                print(entry)\n",
    "    else:\n",
    "        queryLog.append([x, doc['sessiontrack2012']['session'][x]['interaction']['query'], doc['sessiontrack2012']['session'][x]['interaction']['@starttime'], '', ''])\n",
    "        if 'clicked' in doc['sessiontrack2012']['session'][x]['interaction'].keys():\n",
    "            if type(doc['sessiontrack2012']['session'][x]['interaction']['clicked']['click']) is list: \n",
    "                for clicks in doc['sessiontrack2012']['session'][x]['interaction']['clicked']['click']:\n",
    "                    queryLog.append([x, doc['sessiontrack2012']['session'][x]['interaction']['query'], clicks['@starttime'], clicks['rank'], doc['sessiontrack2012']['session'][x]['interaction']['results']['result'][int(clicks['rank'])-1]['url']]) \n",
    "                pass\n",
    "            else:\n",
    "                queryLog.append([x, doc['sessiontrack2012']['session'][x]['interaction']['query'], doc['sessiontrack2012']['session'][x]['interaction']['clicked']['click']['@starttime'], doc['sessiontrack2012']['session'][x]['interaction']['clicked']['click']['rank'], doc['sessiontrack2012']['session'][x]['interaction']['results']['result'][int(doc['sessiontrack2012']['session'][x]['interaction']['clicked']['click']['rank'])-1]['url']])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DataSources/TREC/sessiontrack2011.xml') as fd:\n",
    "    doc = xmltodict.parse(fd.read())\n",
    "for x in range(75):\n",
    "    #print(type(doc['sessiontrack2014']['session'][x]['interaction']))\n",
    "    if type(doc['sessiontrack2011']['session'][x]['interaction']) is list:\n",
    "        for entry in (doc['sessiontrack2011']['session'][x]['interaction']):\n",
    "            #print(type(entry))\n",
    "            if not isinstance(entry, str):\n",
    "                queryLog.append([x, entry['query'], entry['@starttime'], '', ''])\n",
    "                \n",
    "                if 'clicked' in entry.keys():\n",
    "                    if type(entry['clicked']) is None:\n",
    "                        break\n",
    "                    if type(entry['clicked']['click']) is list: \n",
    "                        #print('list')\n",
    "                        for clicks in entry['clicked']['click']:\n",
    "                            #print(clicks['rank'])\n",
    "                            if int(clicks['rank'])-1 <10:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-1]['url']])\n",
    "                            elif int(clicks['rank'])-1 <20:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-11]['url']])\n",
    "                            elif int(clicks['rank'])-1 <30:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-21]['url']])\n",
    "                            elif int(clicks['rank'])-1 <40:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-31]['url']])\n",
    "                            elif int(clicks['rank'])-1 <50:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-41]['url']])\n",
    "                            elif int(clicks['rank'])-1 <60:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-51]['url']])\n",
    "                            elif int(clicks['rank'])-1 <70:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-61]['url']])\n",
    "                            else:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-71]['url']])\n",
    "                    else:\n",
    "                        #print(int(entry['clicked']['click']['rank'])-1)\n",
    "                        if (int(entry['clicked']['click']['rank'])-1) < 10:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-1]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 20:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-11]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 30:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-21]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 40:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-31]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 50:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-41]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 60:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-51]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 70:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-61]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 80:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-71]['url']])\n",
    "                        else:  \n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-81]['url']])\n",
    "            else:\n",
    "                print(entry)\n",
    "    else:\n",
    "        queryLog.append([x, doc['sessiontrack2011']['session'][x]['interaction']['query'], doc['sessiontrack2011']['session'][x]['interaction']['@starttime'], '', ''])\n",
    "        if 'clicked' in doc['sessiontrack2011']['session'][x]['interaction'].keys():\n",
    "            if type(doc['sessiontrack2011']['session'][x]['interaction']['clicked']['click']) is list: \n",
    "                for clicks in doc['sessiontrack2011']['session'][x]['interaction']['clicked']['click']:\n",
    "                    queryLog.append([x, doc['sessiontrack2011']['session'][x]['interaction']['query'], clicks['@starttime'], clicks['rank'], doc['sessiontrack2011']['session'][x]['interaction']['results']['result'][int(clicks['rank'])-1]['url']]) \n",
    "                pass\n",
    "            else:\n",
    "                queryLog.append([x, doc['sessiontrack2011']['session'][x]['interaction']['query'], doc['sessiontrack2011']['session'][x]['interaction']['clicked']['click']['@starttime'], doc['sessiontrack2011']['session'][x]['interaction']['clicked']['click']['rank'], doc['sessiontrack2011']['session'][x]['interaction']['results']['result'][int(doc['sessiontrack2011']['session'][x]['interaction']['clicked']['click']['rank'])-1]['url']])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentUser = queryLog[0][0]\n",
    "sessions = []\n",
    "session = []\n",
    "for row in queryLog:\n",
    "    tempUser = row[0]\n",
    "    if(tempUser != currentUser):\n",
    "        sessions.append(session)\n",
    "        session = []\n",
    "        currentUser = tempUser\n",
    "    session.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( sessions, open( \"Pickles/NotArchPickles/TRECS.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bl4z3/miniconda3/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "TRECS = np.asarray(pickle.load( open( \"Pickles/NotArchPickles/TRECS.p\", \"rb\" ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1557"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TRECS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess timestamp on TREC sessions to match AOL logs\n",
    "\n",
    "for session in TRECS[1386:]:\n",
    "    initialTimeStamp = session[0][2].split('.')[0]\n",
    "    date = datetime.strptime(initialTimeStamp, \"%H:%M:%S\")\n",
    "    tempTime = datetime.timestamp(date)\n",
    "    for query in session:\n",
    "        date2 = datetime.strptime(query[2].split('.')[0], \"%H:%M:%S\")\n",
    "        tempTime2 = datetime.timestamp(date2)   \n",
    "        query[2] = tempTime2 - tempTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1557"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TRECS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only add sessions that have a click\n",
    "\n",
    "newTRECS = []\n",
    "count = 0\n",
    "for session in TRECS:\n",
    "    for query in session:\n",
    "        if query[3]:\n",
    "            newTRECS.append(session)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRECS = newTRECS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TRECS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Sessions With Clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "duraArch = np.asarray(pickle.load( open( \"Pickles/archPickles/duraArch.p\", \"rb\" ) ))\n",
    "prefArch = np.asarray(pickle.load( open( \"Pickles/archPickles/prefArch.p\", \"rb\" ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bl4z3/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "randomNotArch = np.random.choice(notArchClick, size=(((len(duraArch) + len(prefArch))*4)-len(TRECS)), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in randomNotArch:\n",
    "    date = datetime.strptime(session[0][2], \"%Y-%m-%d %H:%M:%S\")\n",
    "    tempTime = datetime.timestamp(date)\n",
    "    for query in session:\n",
    "        date2 = datetime.strptime(query[2], \"%Y-%m-%d %H:%M:%S\")\n",
    "        tempTime2 = datetime.timestamp(date2)   \n",
    "        query[2] = tempTime2 - tempTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "notArchComplete =  np.concatenate((randomNotArch, TRECS), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31920"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(notArchComplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "archComplete = np.concatenate((duraArch, prefArch), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in archComplete:\n",
    "    date = datetime.strptime(session[0][2], \"%Y-%m-%d %H:%M:%S\")\n",
    "    tempTime = datetime.timestamp(date)\n",
    "    for query in session:\n",
    "        date2 = datetime.strptime(query[2], \"%Y-%m-%d %H:%M:%S\")\n",
    "        tempTime2 = datetime.timestamp(date2)   \n",
    "        query[2] = tempTime2 - tempTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7980"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(archComplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( archComplete, open( \"DataSets/SWC/ArchComplete.p\", \"wb\" ) )\n",
    "pickle.dump( notArchComplete, open( \"DataSets/SWC/NotArchComplete.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Query Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "kidsQ = []\n",
    "with open('DataSources/Sven/ChildrenQueries.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        kidsQ.append(row[0][:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRECQ = []\n",
    "for session in TRECS:\n",
    "    for query in session:\n",
    "        TRECQ.append(query[1])\n",
    "TRECQ = list(set(TRECQ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRECQSelected = np.random.choice(TRECQ, size=(len(kidsQ)*4), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1204"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TRECQSelected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( TRECQSelected, open( \"DataSets/SQS/SQSNA.p\", \"wb\" ) )\n",
    "pickle.dump( kidsQ, open( \"DataSets/SQS/SQSA.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Preprocessing\n",
    "\n",
    "There is an issue with how clicks and queries are represented, the following steps clearly seperates the two allowing for experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "archComplete = pickle.load( open( \"DataSets/SWC/ArchComplete.p\", \"rb\" ) )\n",
    "notArchComplete = pickle.load( open( \"DataSets/SWC/NotArchComplete.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitQueryClicksAOL(data):\n",
    "    sample = []\n",
    "    for session in data:\n",
    "        currentQuery = session[0][1]\n",
    "        first = True\n",
    "        currentTime = -1\n",
    "        newSession = []\n",
    "        for query in session:\n",
    "            if first and query[1] == currentQuery and (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif first and query[1] == currentQuery and not (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "            elif query[1] != currentQuery and (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif query[1] != currentQuery and not (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "            # and has a click\n",
    "            # and doesn't have a click\n",
    "            ##if the query is the same \n",
    "            elif query[1] == currentQuery and (query[2] != currentTime) and (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif query[1] == currentQuery and (query[2] == currentTime) and (query[3]): \n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif query[1] == currentQuery and (query[2] == currentTime) and not (query[3]): \n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "            elif query[1] == currentQuery and not (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "            currentQuery = query[1]\n",
    "            currentTime = query[2]\n",
    "            first = False\n",
    "        sample.append(newSession)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitQueryClicksTREC(data):\n",
    "    sample = []\n",
    "    for session in data:\n",
    "        currentQuery = session[0][1]\n",
    "        first = True\n",
    "        currentTime = -1\n",
    "        newSession = []\n",
    "        for query in session:\n",
    "            if first and query[1] == currentQuery and (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif first and query[1] == currentQuery and not (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "            elif query[1] != currentQuery and (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif query[1] != currentQuery and not (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "            # and has a click\n",
    "            # and doesn't have a click\n",
    "            ##if the query is the same \n",
    "            elif query[1] == currentQuery and (query[2] != currentTime) and (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif query[1] == currentQuery and (query[2] == currentTime): \n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif query[1] == currentQuery and not (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "            currentQuery = query[1]\n",
    "            currentTime = query[2]\n",
    "            first = False\n",
    "            #print(query)\n",
    "        sample.append(newSession)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "archCompleteProc = splitQueryClicksAOL(archComplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "notArchCompleteProc = np.concatenate((splitQueryClicksAOL(notArchComplete[:31020]), splitQueryClicksTREC(notArchComplete[31020:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( archCompleteProc, open( \"DataSets/SWC/SWCA.p\", \"wb\" ) )\n",
    "pickle.dump( notArchCompleteProc, open( \"DataSets/SWC/SWCNA.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Preprocessing Pt. 2\n",
    "\n",
    "These next steps remove some bad queries, as the AOL query logs replace some queries with '-'. Further more, some punctuation is represented in it's ascii format. We replace that too. If this causes the session to contain no clicks, we remove that session; as one of our ground rules for these kind of sessions is they must contain one click. Furthermore, we convert all sessions into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = pickle.load( open( \"DataSets/SWC/SWCA.p\", \"rb\" ) )\n",
    "notArch = pickle.load( open( \"DataSets/SWC/SWCNA.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7980/7980 [00:00<00:00, 276604.65it/s]\n"
     ]
    }
   ],
   "source": [
    "newArch = []\n",
    "count = 0\n",
    "archQL = []\n",
    "pattern = ' 20[^0-9. ]'\n",
    "with tqdm(total = len(arch) ) as pbar:\n",
    "    for session in arch:\n",
    "        order = 0\n",
    "        for query in session:\n",
    "            if query[1] == '-':\n",
    "                 pass\n",
    "            else:\n",
    "                if ' 20' in query[1]:\n",
    "                    result = re.search(pattern, query[1])\n",
    "                    if result:\n",
    "                        query[1]= re.sub(' 20', \" \", query[1])\n",
    "                        #print(query)\n",
    "                query[0] = count\n",
    "                query.append(order)\n",
    "                archQL.append(query)\n",
    "                order += 1\n",
    "        count +=1\n",
    "        pbar.update()\n",
    "archPD = pd.DataFrame(archQL, columns = [\"sID\", \"query\", \"timestamp\",\"click\",\"website\",\"type\",\"order\"] )  \n",
    "archPD['class'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "notArchQL = []\n",
    "for session in notArch:\n",
    "    order = 0\n",
    "    for query in session:\n",
    "        if query[1] == '-':\n",
    "            pass\n",
    "        else:\n",
    "            if ' 20' in query[1]:\n",
    "                result = re.search(pattern, query[1])\n",
    "                if result:\n",
    "                    query[1]= re.sub(' 20', \" \", query[1])\n",
    "            query[0] = count\n",
    "            query.append(order)\n",
    "            notArchQL.append(query)\n",
    "            order += 1\n",
    "    count +=1\n",
    "notArchPD = pd.DataFrame(notArchQL, columns = [\"sID\", \"query\", \"timestamp\",\"click\",\"website\",\"type\",\"order\"] )  \n",
    "notArchPD['class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "allSessions = pd.concat([archPD, notArchPD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "toKeep = (allSessions.groupby('sID')['type'].nunique()==2)\n",
    "toKeep = pd.DataFrame(toKeep)\n",
    "toKeep = toKeep[toKeep['type']==True].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "allSessions = allSessions[allSessions['sID'].isin(toKeep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sID</th>\n",
       "      <th>query</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>click</th>\n",
       "      <th>website</th>\n",
       "      <th>type</th>\n",
       "      <th>order</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>bob the builder</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>bob the builder</td>\n",
       "      <td>13</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>bob the builder</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>http://nickjr.co.uk</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>bob the builder</td>\n",
       "      <td>259</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Q</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>bob the builder</td>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.hitentertainment.com</td>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196916</th>\n",
       "      <td>39898</td>\n",
       "      <td>history of crossword puzzle</td>\n",
       "      <td>142</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Q</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196917</th>\n",
       "      <td>39898</td>\n",
       "      <td>history of crossword puzzle</td>\n",
       "      <td>142</td>\n",
       "      <td>7</td>\n",
       "      <td>http://www.edinformatics.com/inventions_invent...</td>\n",
       "      <td>C</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196918</th>\n",
       "      <td>39899</td>\n",
       "      <td>\"hospital anxiety and depression scale\" scales...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196919</th>\n",
       "      <td>39899</td>\n",
       "      <td>\"hospital anxiety and depression scale\" scales...</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196920</th>\n",
       "      <td>39899</td>\n",
       "      <td>\"hospital anxiety and depression scale\" scales...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>http://idacc.healthbase.info/questionnaires.html</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230362 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sID                                              query timestamp  \\\n",
       "0           0                                    bob the builder        12   \n",
       "1           0                                    bob the builder        13   \n",
       "2           0                                    bob the builder        13   \n",
       "3           0                                    bob the builder       259   \n",
       "4           0                                    bob the builder       259   \n",
       "...       ...                                                ...       ...   \n",
       "196916  39898                        history of crossword puzzle       142   \n",
       "196917  39898                        history of crossword puzzle       142   \n",
       "196918  39899  \"hospital anxiety and depression scale\" scales...         0   \n",
       "196919  39899  \"hospital anxiety and depression scale\" scales...         7   \n",
       "196920  39899  \"hospital anxiety and depression scale\" scales...         7   \n",
       "\n",
       "       click                                            website type  order  \\\n",
       "0                                                                  Q      0   \n",
       "1                                                                  Q      1   \n",
       "2          5                                http://nickjr.co.uk    C      2   \n",
       "3                                                                  Q      3   \n",
       "4          1                    http://www.hitentertainment.com    C      4   \n",
       "...      ...                                                ...  ...    ...   \n",
       "196916                                                             Q      7   \n",
       "196917     7  http://www.edinformatics.com/inventions_invent...    C      8   \n",
       "196918                                                             Q      0   \n",
       "196919                                                             Q      1   \n",
       "196920     1   http://idacc.healthbase.info/questionnaires.html    C      2   \n",
       "\n",
       "        class  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "196916      0  \n",
       "196917      0  \n",
       "196918      0  \n",
       "196919      0  \n",
       "196920      0  \n",
       "\n",
       "[230362 rows x 8 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allSessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(allSessions, open( \"DataSets/SWC/SWC.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
