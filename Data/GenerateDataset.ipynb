{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in this notebook generates the Data Sets for our experiments by drawing on several data sources. Processing the AOL query logs can take 6-10 hours, which are then saved as pickles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import pickle\n",
    "import xmltodict\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitQueryClicksAOL(data):\n",
    "    sample = []\n",
    "    for session in data:\n",
    "        currentQuery = session[0][1]\n",
    "        first = True\n",
    "        currentTime = -1\n",
    "        newSession = []\n",
    "        for query in session:\n",
    "            if first and query[1] == currentQuery and (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif first and query[1] == currentQuery and not (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "            elif query[1] != currentQuery and (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif query[1] != currentQuery and not (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "            elif query[1] == currentQuery and (query[2] != currentTime) and (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif query[1] == currentQuery and (query[2] == currentTime) and (query[3]): \n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif query[1] == currentQuery and (query[2] == currentTime) and not (query[3]): \n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "            elif query[1] == currentQuery and not (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "            currentQuery = query[1]\n",
    "            currentTime = query[2]\n",
    "            first = False\n",
    "        sample.append(newSession)\n",
    "    return sample\n",
    "\n",
    "def splitQueryClicksTREC(data):\n",
    "    sample = []\n",
    "    for session in data:\n",
    "        currentQuery = session[0][1]\n",
    "        first = True\n",
    "        currentTime = -1\n",
    "        newSession = []\n",
    "        for query in session:\n",
    "            if first and query[1] == currentQuery and (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif first and query[1] == currentQuery and not (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "            elif query[1] != currentQuery and (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif query[1] != currentQuery and not (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "            elif query[1] == currentQuery and (query[2] != currentTime) and (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif query[1] == currentQuery and (query[2] == currentTime): \n",
    "                newSession.append([query[0],query[1],query[2],query[3],query[4],'C'])\n",
    "            elif query[1] == currentQuery and not (query[3]):\n",
    "                newSession.append([query[0],query[1],query[2],'','','Q'])\n",
    "            currentQuery = query[1]\n",
    "            currentTime = query[2]\n",
    "            first = False\n",
    "        sample.append(newSession)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DMOZ\n",
    "\n",
    "This loads the DMOZ tages which are used to determine whether a website should be tagged as \"designed for children\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sterSites = []\n",
    "with open('DataSources/DMOZ/URL Classification.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "        for row in csv_reader:\n",
    "            if(row[2] == 'Kids'):\n",
    "                sterSites.append(row[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Process AOL\n",
    "\n",
    "This block of code loads the AOL query logs and seperates sessions into two types, one that contain websites designed for our Stereotype, and sesions that do not. This process can take 40-60 minutes for each query log, for a total of 400-600 minutes; hence the pickle files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "\n",
    "#loads query logs\n",
    "for filename in glob.glob(\"DataSources/AOL/*.txt\"):\n",
    "    queryLog = []\n",
    "    with open(filename) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter = '\\t')\n",
    "        lineCount = 0\n",
    "        for row in csv_reader:\n",
    "            if(lineCount > 0):\n",
    "                queryLog.append(row)\n",
    "            lineCount += 1\n",
    "    \n",
    "    currentUser = queryLog[0][0]\n",
    "    date = datetime.strptime(queryLog[0][2], \"%Y-%m-%d %H:%M:%S\")\n",
    "    currentTime = datetime.timestamp(date)\n",
    "\n",
    "    sessions = []\n",
    "    session = []\n",
    "    \n",
    "    #seperates query logs into sessions\n",
    "    for row in queryLog:\n",
    "        tempUser = row[0]\n",
    "        date = datetime.strptime(row[2], \"%Y-%m-%d %H:%M:%S\")\n",
    "        tempTime = datetime.timestamp(date)\n",
    "        if(tempUser != currentUser):\n",
    "            sessions.append(session)\n",
    "            session = []\n",
    "            currentUser = tempUser\n",
    "            date = datetime.strptime(row[2], \"%Y-%m-%d %H:%M:%S\")\n",
    "            tempTime = datetime.timestamp(date)\n",
    "            currentTime = tempTime\n",
    "        if(tempTime > (currentTime + (60*60))):\n",
    "            sessions.append(session)\n",
    "            session = []\n",
    "            currentTime = tempTime\n",
    "        session.append(row)\n",
    "  \n",
    "\n",
    "    sterSessions = []\n",
    "    notSterSessions = []\n",
    "    ster = False\n",
    "    \n",
    "    #seperates sessions into those that do, or do not, contain a click \n",
    "    #on a website for our archetype\n",
    "    with tqdm(total=len(sessions)) as pbar:\n",
    "        for session in sessions:\n",
    "            for query in session:\n",
    "                if query[4] in sterSites:\n",
    "                    sterSessions.append(session)\n",
    "                    ster = True\n",
    "                    break\n",
    "            if ster == False:\n",
    "                notSterSessions.append(session)\n",
    "            else:\n",
    "                ster = False\n",
    "            pbar.update(1)\n",
    "   \n",
    "\n",
    "    pickle.dump( sterSessions, open( \"Pickles/SterPickles/Ster\"+ str(count) +\".p\", \"wb\" ) )\n",
    "    pickle.dump( notSterSessions, open( \"Pickles/NotSterPickles/NotSter\"+ str(count) +\".p\", \"wb\" ) )\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate Stereotype Sessions\n",
    "\n",
    "Opens all pickles that contain sessions with clicks on websites designated as for our Stereotype, and then further seperates them into sessions we label as generated by our Stereotype, and session that aren't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19139/19139 [01:35<00:00, 201.31it/s]\n"
     ]
    }
   ],
   "source": [
    "ster1 = np.asarray(pickle.load( open( \"Pickles/SterPickles/Ster1.p\", \"rb\" ) ), dtype=object)\n",
    "ster2 = np.asarray(pickle.load( open( \"Pickles/SterPickles/Ster2.p\", \"rb\" ) ), dtype=object)\n",
    "ster3 = np.asarray(pickle.load( open( \"Pickles/SterPickles/Ster3.p\", \"rb\" ) ), dtype=object)\n",
    "ster4 = np.asarray(pickle.load( open( \"Pickles/SterPickles/Ster4.p\", \"rb\" ) ), dtype=object)\n",
    "ster5 = np.asarray(pickle.load( open( \"Pickles/SterPickles/Ster5.p\", \"rb\" ) ), dtype=object)\n",
    "ster6 = np.asarray(pickle.load( open( \"Pickles/SterPickles/Ster6.p\", \"rb\" ) ), dtype=object)\n",
    "ster7 = np.asarray(pickle.load( open( \"Pickles/SterPickles/Ster7.p\", \"rb\" ) ), dtype=object)\n",
    "ster8 = np.asarray(pickle.load( open( \"Pickles/SterPickles/Ster8.p\", \"rb\" ) ), dtype=object)\n",
    "ster9 = np.asarray(pickle.load( open( \"Pickles/SterPickles/Ster9.p\", \"rb\" ) ), dtype=object)\n",
    "ster10 = np.asarray(pickle.load( open( \"Pickles/SterPickles/Ster10.p\", \"rb\" ) ), dtype=object)\n",
    "\n",
    "ster = np.concatenate((ster1, ster2, ster3, ster4, ster5, ster6, ster7, ster8, ster9, ster10), axis=0)\n",
    "\n",
    "#Removes all sessions that have more than 200 hundred entries \n",
    "\n",
    "sterRefined = []\n",
    "for session in ster:\n",
    "    if len(session) < 200:\n",
    "        sterRefined.append(session)\n",
    "\n",
    "prefSter = [] # Sessions that exclusively click on sites designed for kids\n",
    "duraSter = [] # Sessions that click on a site for kids and have a session length of less than 6 minutes\n",
    "notSter = [] # Sessions that belong to neither of the previous two\n",
    "\n",
    "with tqdm(total=len(sterRefined)) as pbar:\n",
    "    for session in sterRefined:\n",
    "        clicks = 0\n",
    "        kClicks = 0\n",
    "        for query in session:\n",
    "            if query[4]:\n",
    "                clicks +=1\n",
    "                if query[4] in sterSites:\n",
    "                    kClicks +=1\n",
    "        if(kClicks/clicks == 1):\n",
    "            prefSter.append(session)\n",
    "        else:\n",
    "\n",
    "            startTime =  datetime.strptime(session[0][2], \"%Y-%m-%d %H:%M:%S\")\n",
    "            startTimeStamp = datetime.timestamp(startTime)\n",
    "            endTime = datetime.strptime(session[len(session)-1][2], \"%Y-%m-%d %H:%M:%S\")\n",
    "            endTimeStamp = datetime.timestamp(endTime)\n",
    "            if(endTimeStamp - startTimeStamp) < (60*6):\n",
    "                duraSter.append(session)\n",
    "            else:\n",
    "                notSter.append(session)\n",
    "        pbar.update()\n",
    "        \n",
    "pickle.dump( notSter, open( \"Pickles/NotSterPickles/NotSter11.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate all sessions that are not our Archetype\n",
    "\n",
    "This block of code concatenates all sessions that are labeled as not being to our Archetype, and removing all sessions that don't have any clicks from that set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10333596/10333596 [01:25<00:00, 120563.12it/s]\n"
     ]
    }
   ],
   "source": [
    "notSter1 = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/NotSter1.p\", \"rb\" )), dtype=object)\n",
    "notSter2 = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/NotSter2.p\", \"rb\" )), dtype=object)\n",
    "notSter3 = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/NotSter3.p\", \"rb\" )), dtype=object)\n",
    "notSter4 = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/NotSter4.p\", \"rb\" )), dtype=object)\n",
    "notSter5 = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/NotSter5.p\", \"rb\" )), dtype=object)\n",
    "notSter6 = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/NotSter6.p\", \"rb\" )), dtype=object)\n",
    "notSter7 = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/NotSter7.p\", \"rb\" )), dtype=object)\n",
    "notSter8 = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/NotSter8.p\", \"rb\" )), dtype=object)\n",
    "notSter9 = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/NotSter9.p\", \"rb\" )), dtype=object)\n",
    "notSter10 = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/NotSter10.p\", \"rb\" )), dtype=object)\n",
    "notSter11 = np.asarray(pickle.load( open( \"Pickles/NotSterPickles/NotSter11.p\", \"rb\" )), dtype=object)\n",
    "\n",
    "notSter = np.concatenate((notSter1, notSter2, notSter3,notSter4,notSter5,notSter6,notSter7,notSter8,notSter9,notSter10, notSter11), axis=0)\n",
    "\n",
    "# Remove all sessions with no clicks\n",
    "notSterClick = []\n",
    "with tqdm(total=len(notSter)) as pbar:\n",
    "    for session in notSter:\n",
    "        for query in session:\n",
    "            if query[3]:\n",
    "                #print(query)\n",
    "                notSterClick.append(session)\n",
    "                break\n",
    "            else:\n",
    "                pass\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process TREC\n",
    "\n",
    "This loads and processes the TREC session track query logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryLog = []\n",
    "with open('DataSources/TREC/sessiontrack2014.xml') as fd:\n",
    "    doc = xmltodict.parse(fd.read())\n",
    "for x in range(len(doc['sessiontrack2014']['session'])):\n",
    "    if type(doc['sessiontrack2014']['session'][x]['interaction']) is list:\n",
    "        for entry in (doc['sessiontrack2014']['session'][x]['interaction']):\n",
    "            #print(type(entry))\n",
    "            if not isinstance(entry, str):\n",
    "                queryLog.append([x, entry['query'], entry['@starttime'], '', ''])\n",
    "                if 'clicked' in entry.keys():\n",
    "                    if type(entry['clicked']['click']) is list: \n",
    "                        #print('list')\n",
    "                        for clicks in entry['clicked']['click']:\n",
    "                            #print(clicks['rank'])\n",
    "                            if int(clicks['rank'])-1 <10:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-1]['url']])\n",
    "                            elif int(clicks['rank'])-1 <20:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-11]['url']])\n",
    "                            elif int(clicks['rank'])-1 <30:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-21]['url']])\n",
    "                            elif int(clicks['rank'])-1 <40:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-31]['url']])\n",
    "                            elif int(clicks['rank'])-1 <50:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-41]['url']])\n",
    "                            elif int(clicks['rank'])-1 <60:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-51]['url']])\n",
    "                            elif int(clicks['rank'])-1 <70:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-61]['url']])\n",
    "                            else:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-71]['url']])\n",
    "                    else:\n",
    "                        if (int(entry['clicked']['click']['rank'])-1) < 10:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-1]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 20:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-11]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 30:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-21]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 40:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-31]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 50:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-41]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 60:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-51]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 70:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-61]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 80:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-71]['url']])\n",
    "                        else:  \n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-81]['url']])\n",
    "            else:\n",
    "                print(entry)\n",
    "    else:\n",
    "        queryLog.append([x, doc['sessiontrack2014']['session'][x]['interaction']['query'], doc['sessiontrack2014']['session'][x]['interaction']['@starttime'], '', ''])\n",
    "        if 'clicked' in doc['sessiontrack2014']['session'][x]['interaction'].keys():\n",
    "            if type(doc['sessiontrack2014']['session'][x]['interaction']['clicked']['click']) is list: \n",
    "                for clicks in doc['sessiontrack2014']['session'][x]['interaction']['clicked']['click']:\n",
    "                    queryLog.append([x, doc['sessiontrack2014']['session'][x]['interaction']['query'], clicks['@starttime'], clicks['rank'], doc['sessiontrack2014']['session'][x]['interaction']['results']['result'][int(clicks['rank'])-1]['url']]) \n",
    "                pass\n",
    "            else:\n",
    "                queryLog.append([x, doc['sessiontrack2014']['session'][x]['interaction']['query'], doc['sessiontrack2014']['session'][x]['interaction']['clicked']['click']['@starttime'], doc['sessiontrack2014']['session'][x]['interaction']['clicked']['click']['rank'], doc['sessiontrack2014']['session'][x]['interaction']['results']['result'][int(doc['sessiontrack2014']['session'][x]['interaction']['clicked']['click']['rank'])-1]['url']])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DataSources/TREC/sessiontrack2013.xml') as fd:\n",
    "    doc = xmltodict.parse(fd.read())\n",
    "for x in range(len(doc['sessiontrack2013']['session'])):\n",
    "    #print(type(doc['sessiontrack2014']['session'][x]['interaction']))\n",
    "    if type(doc['sessiontrack2013']['session'][x]['interaction']) is list:\n",
    "        for entry in (doc['sessiontrack2013']['session'][x]['interaction']):\n",
    "            #print(type(entry))\n",
    "            if not isinstance(entry, str):\n",
    "                queryLog.append([x, entry['query'], entry['@starttime'], '', ''])\n",
    "                if 'clicked' in entry.keys():\n",
    "                    if type(entry['clicked']['click']) is list: \n",
    "                        #print('list')\n",
    "                        for clicks in entry['clicked']['click']:\n",
    "                            #print(clicks['rank'])\n",
    "                            if int(clicks['rank'])-1 <10:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-1]['url']])\n",
    "                            elif int(clicks['rank'])-1 <20:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-11]['url']])\n",
    "                            elif int(clicks['rank'])-1 <30:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-21]['url']])\n",
    "                            elif int(clicks['rank'])-1 <40:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-31]['url']])\n",
    "                            elif int(clicks['rank'])-1 <50:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-41]['url']])\n",
    "                            elif int(clicks['rank'])-1 <60:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-51]['url']])\n",
    "                            elif int(clicks['rank'])-1 <70:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-61]['url']])\n",
    "                            else:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-71]['url']])\n",
    "                    else:\n",
    "                        #print(int(entry['clicked']['click']['rank'])-1)\n",
    "                        if (int(entry['clicked']['click']['rank'])-1) < 10:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-1]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 20:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-11]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 30:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-21]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 40:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-31]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 50:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-41]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 60:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-51]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 70:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-61]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 80:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-71]['url']])\n",
    "                        else:  \n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-81]['url']])\n",
    "            else:\n",
    "                queryLog.append(entry)\n",
    "    else:\n",
    "        queryLog.append([x, doc['sessiontrack2013']['session'][x]['interaction']['query'], doc['sessiontrack2013']['session'][x]['interaction']['@starttime'], '', ''])\n",
    "        if 'clicked' in doc['sessiontrack2013']['session'][x]['interaction'].keys():\n",
    "            if type(doc['sessiontrack2013']['session'][x]['interaction']['clicked']['click']) is list: \n",
    "                for clicks in doc['sessiontrack2013']['session'][x]['interaction']['clicked']['click']:\n",
    "                    queryLog.append([x, doc['sessiontrack2013']['session'][x]['interaction']['query'], clicks['@starttime'], clicks['rank'], doc['sessiontrack2013']['session'][x]['interaction']['results']['result'][int(clicks['rank'])-1]['url']]) \n",
    "                pass\n",
    "            else:\n",
    "                queryLog.append([x, doc['sessiontrack2013']['session'][x]['interaction']['query'], doc['sessiontrack2013']['session'][x]['interaction']['clicked']['click']['@starttime'], doc['sessiontrack2013']['session'][x]['interaction']['clicked']['click']['rank'], doc['sessiontrack2013']['session'][x]['interaction']['results']['result'][int(doc['sessiontrack2013']['session'][x]['interaction']['clicked']['click']['rank'])-1]['url']])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DataSources/TREC/sessiontrack2012.xml') as fd:\n",
    "    doc = xmltodict.parse(fd.read())\n",
    "for x in range(len(doc['sessiontrack2012']['session'])):\n",
    "    if type(doc['sessiontrack2012']['session'][x]['interaction']) is list:\n",
    "        for entry in (doc['sessiontrack2012']['session'][x]['interaction']):\n",
    "            #print(type(entry))\n",
    "            if not isinstance(entry, str):\n",
    "                queryLog.append([x, entry['query'], entry['@starttime'], '', ''])\n",
    "                \n",
    "                if 'clicked' in entry.keys():\n",
    "                    if type(entry['clicked']) is None:\n",
    "                        break\n",
    "                    if type(entry['clicked']['click']) is list: \n",
    "                        #print('list')\n",
    "                        for clicks in entry['clicked']['click']:\n",
    "                            #print(clicks['rank'])\n",
    "                            if int(clicks['rank'])-1 <10:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-1]['url']])\n",
    "                            elif int(clicks['rank'])-1 <20:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-11]['url']])\n",
    "                            elif int(clicks['rank'])-1 <30:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-21]['url']])\n",
    "                            elif int(clicks['rank'])-1 <40:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-31]['url']])\n",
    "                            elif int(clicks['rank'])-1 <50:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-41]['url']])\n",
    "                            elif int(clicks['rank'])-1 <60:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-51]['url']])\n",
    "                            elif int(clicks['rank'])-1 <70:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-61]['url']])\n",
    "                            else:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-71]['url']])\n",
    "                    else:\n",
    "                        #print(int(entry['clicked']['click']['rank'])-1)\n",
    "                        if (int(entry['clicked']['click']['rank'])-1) < 10:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-1]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 20:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-11]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 30:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-21]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 40:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-31]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 50:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-41]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 60:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-51]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 70:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-61]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 80:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-71]['url']])\n",
    "                        else:  \n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-81]['url']])\n",
    "            else:\n",
    "                print(entry)\n",
    "    else:\n",
    "        queryLog.append([x, doc['sessiontrack2012']['session'][x]['interaction']['query'], doc['sessiontrack2012']['session'][x]['interaction']['@starttime'], '', ''])\n",
    "        if 'clicked' in doc['sessiontrack2012']['session'][x]['interaction'].keys():\n",
    "            if type(doc['sessiontrack2012']['session'][x]['interaction']['clicked']['click']) is list: \n",
    "                for clicks in doc['sessiontrack2012']['session'][x]['interaction']['clicked']['click']:\n",
    "                    queryLog.append([x, doc['sessiontrack2012']['session'][x]['interaction']['query'], clicks['@starttime'], clicks['rank'], doc['sessiontrack2012']['session'][x]['interaction']['results']['result'][int(clicks['rank'])-1]['url']]) \n",
    "                pass\n",
    "            else:\n",
    "                queryLog.append([x, doc['sessiontrack2012']['session'][x]['interaction']['query'], doc['sessiontrack2012']['session'][x]['interaction']['clicked']['click']['@starttime'], doc['sessiontrack2012']['session'][x]['interaction']['clicked']['click']['rank'], doc['sessiontrack2012']['session'][x]['interaction']['results']['result'][int(doc['sessiontrack2012']['session'][x]['interaction']['clicked']['click']['rank'])-1]['url']])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DataSources/TREC/sessiontrack2011.xml') as fd:\n",
    "    doc = xmltodict.parse(fd.read())\n",
    "for x in range(len(doc['sessiontrack2011']['session'])):\n",
    "    if type(doc['sessiontrack2011']['session'][x]['interaction']) is list:\n",
    "        for entry in (doc['sessiontrack2011']['session'][x]['interaction']):\n",
    "            if not isinstance(entry, str):\n",
    "                queryLog.append([x, entry['query'], entry['@starttime'], '', ''])\n",
    "           \n",
    "                if 'clicked' in entry.keys():\n",
    "                    if type(entry['clicked']) is None:\n",
    "                        break\n",
    "                    if type(entry['clicked']['click']) is list: \n",
    "                        #print('list')\n",
    "                        for clicks in entry['clicked']['click']:\n",
    "                            #print(clicks['rank'])\n",
    "                            if int(clicks['rank'])-1 <10:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-1]['url']])\n",
    "                            elif int(clicks['rank'])-1 <20:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-11]['url']])\n",
    "                            elif int(clicks['rank'])-1 <30:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-21]['url']])\n",
    "                            elif int(clicks['rank'])-1 <40:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-31]['url']])\n",
    "                            elif int(clicks['rank'])-1 <50:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-41]['url']])\n",
    "                            elif int(clicks['rank'])-1 <60:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-51]['url']])\n",
    "                            elif int(clicks['rank'])-1 <70:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-61]['url']])\n",
    "                            else:\n",
    "                                queryLog.append([x, entry['query'], clicks['@starttime'], clicks['rank'], entry['results']['result'][int(clicks['rank'])-71]['url']])\n",
    "                    else:\n",
    "                        #print(int(entry['clicked']['click']['rank'])-1)\n",
    "                        if (int(entry['clicked']['click']['rank'])-1) < 10:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-1]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 20:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-11]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 30:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-21]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 40:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-31]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 50:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-41]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 60:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-51]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 70:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-61]['url']])\n",
    "                        elif (int(entry['clicked']['click']['rank'])-1) < 80:\n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-71]['url']])\n",
    "                        else:  \n",
    "                            queryLog.append([x, entry['query'], entry['clicked']['click']['@starttime'], entry['clicked']['click']['rank'], entry['results']['result'][int(entry['clicked']['click']['rank'])-81]['url']])\n",
    "            else:\n",
    "                print(entry)\n",
    "    else:\n",
    "        queryLog.append([x, doc['sessiontrack2011']['session'][x]['interaction']['query'], doc['sessiontrack2011']['session'][x]['interaction']['@starttime'], '', ''])\n",
    "        if 'clicked' in doc['sessiontrack2011']['session'][x]['interaction'].keys():\n",
    "            if type(doc['sessiontrack2011']['session'][x]['interaction']['clicked']['click']) is list: \n",
    "                for clicks in doc['sessiontrack2011']['session'][x]['interaction']['clicked']['click']:\n",
    "                    queryLog.append([x, doc['sessiontrack2011']['session'][x]['interaction']['query'], clicks['@starttime'], clicks['rank'], doc['sessiontrack2011']['session'][x]['interaction']['results']['result'][int(clicks['rank'])-1]['url']]) \n",
    "                pass\n",
    "            else:\n",
    "                queryLog.append([x, doc['sessiontrack2011']['session'][x]['interaction']['query'], doc['sessiontrack2011']['session'][x]['interaction']['clicked']['click']['@starttime'], doc['sessiontrack2011']['session'][x]['interaction']['clicked']['click']['rank'], doc['sessiontrack2011']['session'][x]['interaction']['results']['result'][int(doc['sessiontrack2011']['session'][x]['interaction']['clicked']['click']['rank'])-1]['url']])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentUser = queryLog[0][0]\n",
    "TRECS = []\n",
    "session = []\n",
    "for row in queryLog:\n",
    "    tempUser = row[0]\n",
    "    if(tempUser != currentUser):\n",
    "        TRECS.append(session)\n",
    "        session = []\n",
    "        currentUser = tempUser\n",
    "    session.append(row)\n",
    "\n",
    "#Preprocess timestamp on TREC sessions to match AOL logs\n",
    "\n",
    "for session in TRECS:\n",
    "    if ':' in str(session[0][2]):\n",
    "        initialTimeStamp = session[0][2].split('.')[0]\n",
    "        date = datetime.strptime(initialTimeStamp, \"%H:%M:%S\")\n",
    "        tempTime = datetime.timestamp(date)\n",
    "        for query in session:\n",
    "            date2 = datetime.strptime(query[2].split('.')[0], \"%H:%M:%S\")\n",
    "            tempTime2 = datetime.timestamp(date2)   \n",
    "            query[2] = tempTime2 - tempTime\n",
    "\n",
    "# Only add sessions that have a click\n",
    "\n",
    "newTRECS = []\n",
    "count = 0\n",
    "for session in TRECS:\n",
    "    for query in session:\n",
    "        if query[3]:\n",
    "            newTRECS.append(session)\n",
    "            break\n",
    "            \n",
    "TRECS = np.array(newTRECS, dtype = 'object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Sessions With Clicks\n",
    "\n",
    "Creates the Sessions With Clicks data set by combining sessions from TREC, as well as those we labeled as belonging to users who are, and are not; our Stereotype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bl4z3/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "randomNotSter = np.random.choice(notSterClick, size=(((len(duraSter) + len(prefSter))*4)-len(TRECS)), replace=False)\n",
    "\n",
    "for session in randomNotSter:\n",
    "    date = datetime.strptime(session[0][2], \"%Y-%m-%d %H:%M:%S\")\n",
    "    tempTime = datetime.timestamp(date)\n",
    "    for query in session:\n",
    "        date2 = datetime.strptime(query[2], \"%Y-%m-%d %H:%M:%S\")\n",
    "        tempTime2 = datetime.timestamp(date2)   \n",
    "        query[2] = tempTime2 - tempTime\n",
    "        \n",
    "notSterComplete =  np.concatenate((randomNotSter, TRECS), axis=0)\n",
    "sterComplete = np.concatenate((duraSter, prefSter), axis=0)\n",
    "\n",
    "for session in sterComplete:\n",
    "    date = datetime.strptime(session[0][2], \"%Y-%m-%d %H:%M:%S\")\n",
    "    tempTime = datetime.timestamp(date)\n",
    "    for query in session:\n",
    "        date2 = datetime.strptime(query[2], \"%Y-%m-%d %H:%M:%S\")\n",
    "        tempTime2 = datetime.timestamp(date2)   \n",
    "        query[2] = tempTime2 - tempTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Query Data Set\n",
    "\n",
    "Creates the Single Query data set from the Sven data source and extracing single queries from the TREC sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sterSQS = [] \n",
    "\n",
    "with open('DataSources/Sven/ChildrenQueries.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        sterSQS.append(row[0][:-2])\n",
    "        \n",
    "notSterSQS = []\n",
    "\n",
    "for session in TRECS:\n",
    "    for query in session:\n",
    "        notSterSQS.append(query[1])\n",
    "\n",
    "notSterSQS = list(set(notSterSQS))\n",
    "notSterSQS = np.random.choice(notSterSQS, size=(len(sterSQS)*4), replace=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Preprocessing\n",
    "\n",
    "There is an issue with how clicks and queries are represented in the AOL query logs, the following steps clearly seperates the two allowing for experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sterCompleteProc = splitQueryClicksAOL(sterComplete)\n",
    "notSterCompleteProc = np.concatenate((splitQueryClicksAOL(notSterComplete[:(len(notSterComplete)-len(TRECS))]), splitQueryClicksTREC(notSterComplete[(len(notSterComplete)-len(TRECS)):])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Preprocessing Pt. 2\n",
    "\n",
    "These next steps remove some bad queries, as the AOL query logs replace some queries with '-'. Further more, some punctuation is represented in it's ascii format. We replace that too. If this causes the session to contain no clicks, we remove that session; as one of our ground rules for these kind of sessions is they must contain one click. Furthermore, we convert all sessions into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7980/7980 [00:00<00:00, 52469.24it/s]\n",
      "100%|██████████| 31920/31920 [00:00<00:00, 48419.74it/s]\n"
     ]
    }
   ],
   "source": [
    "newSter = []\n",
    "notSterQL = []\n",
    "sterQL = []\n",
    "count = 0\n",
    "\n",
    "pattern = ' 20[^0-9. ]'\n",
    "with tqdm(total = len(sterCompleteProc) ) as pbar:\n",
    "    for session in sterCompleteProc:\n",
    "        order = 0\n",
    "        for query in session:\n",
    "            if query[1] == '-':\n",
    "                 pass\n",
    "            else:\n",
    "                if ' 20' in query[1]:\n",
    "                    result = re.search(pattern, query[1])\n",
    "                    if result:\n",
    "                        query[1]= re.sub(' 20', \" \", query[1])\n",
    "                        #print(query)\n",
    "                query[0] = count\n",
    "                query.append(order)\n",
    "                sterQL.append(query)\n",
    "                order += 1\n",
    "        count +=1\n",
    "        pbar.update()\n",
    "        \n",
    "sterPD = pd.DataFrame(sterQL, columns = [\"sID\", \"query\", \"timestamp\",\"click\",\"website\",\"type\",\"order\"] )  \n",
    "sterPD['class'] = 1\n",
    "\n",
    "with tqdm(total = len(notSterCompleteProc) ) as pbar:\n",
    "    for session in notSterCompleteProc:\n",
    "        order = 0\n",
    "        for query in session:\n",
    "            if query[1] == '-':\n",
    "                pass\n",
    "            else:\n",
    "                if ' 20' in query[1]:\n",
    "                    result = re.search(pattern, query[1])\n",
    "                    if result:\n",
    "                        query[1]= re.sub(' 20', \" \", query[1])\n",
    "                query[0] = count\n",
    "                query.append(order)\n",
    "                notSterQL.append(query)\n",
    "                order += 1\n",
    "        count +=1\n",
    "        pbar.update()\n",
    "        \n",
    "notSterPD = pd.DataFrame(notSterQL, columns = [\"sID\", \"query\", \"timestamp\",\"click\",\"website\",\"type\",\"order\"] )  \n",
    "notSterPD['class'] = 0\n",
    "\n",
    "allSessions = pd.concat([sterPD, notSterPD])\n",
    "\n",
    "toKeep = (allSessions.groupby('sID')['type'].nunique()==2) ##checks to see if a session has both a Click and a Query\n",
    "toKeep = pd.DataFrame(toKeep)\n",
    "toKeep = toKeep[toKeep['type']==True].index\n",
    "\n",
    "allSessions = allSessions[allSessions['sID'].isin(toKeep)]\n",
    "\n",
    "pickle.dump(allSessions, open( \"DataSets/SWC/SWC.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Preprocessing Pt. 3\n",
    "\n",
    "In this following block of code we preprocess SQS into a usable data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "notSterList = []\n",
    "sterList = []\n",
    "count = allSessions['sID'].max()\n",
    "\n",
    "for entry in notSterSQS:\n",
    "    notSterList.append([entry,count,0])\n",
    "    count +=1\n",
    "notSterSQS = pd.DataFrame(data = notSterList, columns = ['query','sID','class'])\n",
    "\n",
    "for entry in sterSQS:\n",
    "    sterList.append([entry,count,1])\n",
    "    count +=1\n",
    "sterSQS = pd.DataFrame(data = sterList, columns = ['query','sID','class'])\n",
    "\n",
    "allSessionsSQS = pd.concat([notSterSQS, sterSQS])\n",
    "\n",
    "pickle.dump(allSessionsSQS, open( \"DataSets/SQS/SQS.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
